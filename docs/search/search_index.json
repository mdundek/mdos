{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the MDos platform MDos is a Kubernetes based application runtime platform, it's aim is to greatly simplify the process of creating, building and deploying applications on a Kubernetes cluster without compromising on security and efficiency This documentation is for the MDos platform Git repository available here MDos as a fully managed cluster stack or simply as a deployment framework 1. As a fully managed cluster and it's dependencies The full instance of MDos is packed with extensions and features that go beyond the basic application deployment needs. It allows you to abstract away concepts such as SSO, certificate management, multi-tenancy on one single cluster along with advanced RBAC features, a private secured registry and more. This is useful if you start from scratch and you are managing your kubernetes cluster yourself versus using a managed Kubernetes cluster such as EKS, GKE, Openshift and so on. Feature request At some point, the full MDos platform will be ported to such environments as well, but for now this is not the case. The community will drive this need, so speak up if you think this is necessary rather sooner than later. 2. And/or as an application deployment framework only (onto your own cluster) If you are managing your own cluster, but you would like to leverage the MDos application deployment framework to manage and deploy your applications onto the cluster, then this is the mode for you. One single and easy to understand YAML file for everything you need, no deep kubernetes knowledge needed, no scattered low level kubernetes resource yaml files and no complex resource matching patterns needed. Managed Kubernetes Clusters such as EKS and Openshift often already come with a few integrated extensions of their own in order to leverage platform specific features such as Ingress, Certificate management and so on. What those platforms do not provide is a framework to simplify your application configuration and deployments with. Developers and devops engineers still need a very good understanding of Kubernetes artifacts and resources in order to deploy their applications onto Kubernetes. Even experienced Kubernetes folks still have to deal with allot of overhead when digging into those yaml files for some advanced use cases. Limitations When deploying MDos in framework only mode, you won't get advanced features such as OIDC SSO authentication, Automated certificate management, managed multi-tenancy and RBAC support or a private registry OOTB. This deployment focuses on the application framework only. With the MDos framework & CLI, this is what a application deployment looks like for yaml config file just like the one on the left: mdos application deploy This will: Build your docker image Push it to the target registry Deploy everything on your Kubernetes cluster Provide you with feedback of how the deployment is going Disclaimer MDos is in beta stage at the moment, it is under development and should not be used in production yet. Before investing more sweat and tears into this, I want to make sure that there is interest from the community first. Please test it, provide some feedback, or even better, join the party in developing it further. If you encounter some miss-behavior, or if you believe something needs to be adapted, create an issue on the mdos git repo and I will come back to you shortly. Why would you want to use it? Let's face it, Kubernetes is great, most probably one of the best Container runtime platforms ever build with almost endless capabilities. It is no surprising that 70% of all companies use Kubernetes in production somewhere in their public / private cloud environnement. That said, it's complexity is often a deterrent, and leads to badly designed deployment scenarios, regularly exposing security threats as well as miss-usage of certain cluster based capabilities, leading to under-utilization of it's capabilities. Companies often end up provisioning multiple Kubernetes clusters to manage multi-tenant scenarios because properly segregating users and projects in a secure way on a single cluster can be complicated to achieve and maintain. Other pain points faced by non kubernetes experts are plentiful: How do you provision your static application volume content to your Pods? How do you secure your applications on the network level? How do you implement SSO and authentication / authorization mechanisms on your applications? My application does not deploy on Kubernetes, I have no idea why that is and how to fix it? The list goes on and on... After having worked on Kubernetes for several years now and managed teams of developers and architects that had to develop and maintain Kubernetes instances, it became clear for me that something had to change. Companies hire developers to build applications that will run on Kubernetes, but in order to develop applications for Kubernetes, you need to have some solid experience in the domain, making you a rather experienced cloud developer with a undeniable high price tag. Unexperienced developers tend to loose allot of time on understanding Kubernetes in the first place, even more time in learning how to use it properly, leading to very expensive development cycles to get basic applications up and running. Financially, this does not make much sense. If every company had to only hire experienced kubernetes developers to get anything done with it, project costs would rapidly spiral out of control, without mentioning the fact that there are not that many skilled kubernetes experts available in the first place. MDos is an attempt to solve some of those complexity issues for developers and companies, letting them focus on developing applications and not about how to get them running securely on Kubernetes. Features Those can be split into 5 families: Application specific resource configurations Deploy and debug your applications Advanced volume and storage workflows Multi-tenant based segregation OIDC / OAuth2 authentication & Application RBAC Cert-Manager for TLS certificate issuer and secret management 1. Application specific resource configurations Using the MDos CLI and a unified mdos.yaml application descriptor file, you can build complex Kubernetes deployment scenarios without any knowledge of Kubernetes resource definition types such as Deployments , StatefulSets , Pods , Services , PV & PVCs , VirtualServices , Secrets , ConfigMaps , NetworkPolicies ... (just to name a few) Therefore, build your applications using higher level artefact that will translate to lower level Kubernetes resource definitions based on Kubernetes best practices. Scaffold a new application workspace Scaffold a application component inside your mdos application Add config files & environment variables to your application components Add secret (sensitive) files and environment variables to your application components Expose your application components to other resources within the cluster Configure hostname based ingress rules to allow access to your application components from outside of the cluster Mount various volume types to your application components ... 2. Deploy and debug your applications One mdos CLI command to deploy your applications and sync static volumes with your pods Get real-time detailed feedback on your deployments, providing valuable feedback on what might go wrong in order to fix it Get all application component logs, including init container logs in case of a failed deployment for instant debugging Aggregate all application & platform logs in Loki, accessible through a dedicated API (TODO) 3. Advanced volume and storage workflows Synchronize / provision static local data with your application component volumes before they start in Kubernetes Provision shared filesystem volumes for your application components (TODO) 4. Multi-tenant based segregation A tenant will get a Kubernetes namespace as well as a dedicated Keycloak client (for user management) You can create users on the platform and link them to one or more tenants Manage user permissions (RBAC) specifically for each tenant namespace / keycloak client Kubernetes namespaces let you take advantage of network and resource segregation mechanisms for each tenant 5. OIDC / OAuth2 authentication & Application RBAC Provision OIDC / OAuth2 based Authentication providers to your cluster ready to use Link OIDC / OAuth2 provisioned providers to your application components to protect those resources (no app changes needed) Assign roles to your users specifically on each tenant / keycloak client, allowing you to implement your ACL logic without having to deal with authentication at all 6. Cert-Manager for TLS certificate issuer and secret management Register Cert-Manager Issuers onto your cluster or namespace Generate and manage certificates / secrets from your Issuers","title":"Home"},{"location":"#welcome-to-the-mdos-platform","text":"MDos is a Kubernetes based application runtime platform, it's aim is to greatly simplify the process of creating, building and deploying applications on a Kubernetes cluster without compromising on security and efficiency This documentation is for the MDos platform Git repository available here","title":"Welcome to the MDos platform"},{"location":"#mdos-as-a-fully-managed-cluster-stack-or-simply-as-a-deployment-framework","text":"","title":"MDos as a fully managed cluster stack or simply as a deployment framework"},{"location":"#1-as-a-fully-managed-cluster-and-its-dependencies","text":"The full instance of MDos is packed with extensions and features that go beyond the basic application deployment needs. It allows you to abstract away concepts such as SSO, certificate management, multi-tenancy on one single cluster along with advanced RBAC features, a private secured registry and more. This is useful if you start from scratch and you are managing your kubernetes cluster yourself versus using a managed Kubernetes cluster such as EKS, GKE, Openshift and so on. Feature request At some point, the full MDos platform will be ported to such environments as well, but for now this is not the case. The community will drive this need, so speak up if you think this is necessary rather sooner than later.","title":"1. As a fully managed cluster and it's dependencies"},{"location":"#2-andor-as-an-application-deployment-framework-only-onto-your-own-cluster","text":"If you are managing your own cluster, but you would like to leverage the MDos application deployment framework to manage and deploy your applications onto the cluster, then this is the mode for you. One single and easy to understand YAML file for everything you need, no deep kubernetes knowledge needed, no scattered low level kubernetes resource yaml files and no complex resource matching patterns needed. Managed Kubernetes Clusters such as EKS and Openshift often already come with a few integrated extensions of their own in order to leverage platform specific features such as Ingress, Certificate management and so on. What those platforms do not provide is a framework to simplify your application configuration and deployments with. Developers and devops engineers still need a very good understanding of Kubernetes artifacts and resources in order to deploy their applications onto Kubernetes. Even experienced Kubernetes folks still have to deal with allot of overhead when digging into those yaml files for some advanced use cases. Limitations When deploying MDos in framework only mode, you won't get advanced features such as OIDC SSO authentication, Automated certificate management, managed multi-tenancy and RBAC support or a private registry OOTB. This deployment focuses on the application framework only. With the MDos framework & CLI, this is what a application deployment looks like for yaml config file just like the one on the left: mdos application deploy This will: Build your docker image Push it to the target registry Deploy everything on your Kubernetes cluster Provide you with feedback of how the deployment is going Disclaimer MDos is in beta stage at the moment, it is under development and should not be used in production yet. Before investing more sweat and tears into this, I want to make sure that there is interest from the community first. Please test it, provide some feedback, or even better, join the party in developing it further. If you encounter some miss-behavior, or if you believe something needs to be adapted, create an issue on the mdos git repo and I will come back to you shortly.","title":"2. And/or as an application deployment framework only (onto your own cluster)"},{"location":"#why-would-you-want-to-use-it","text":"Let's face it, Kubernetes is great, most probably one of the best Container runtime platforms ever build with almost endless capabilities. It is no surprising that 70% of all companies use Kubernetes in production somewhere in their public / private cloud environnement. That said, it's complexity is often a deterrent, and leads to badly designed deployment scenarios, regularly exposing security threats as well as miss-usage of certain cluster based capabilities, leading to under-utilization of it's capabilities. Companies often end up provisioning multiple Kubernetes clusters to manage multi-tenant scenarios because properly segregating users and projects in a secure way on a single cluster can be complicated to achieve and maintain. Other pain points faced by non kubernetes experts are plentiful: How do you provision your static application volume content to your Pods? How do you secure your applications on the network level? How do you implement SSO and authentication / authorization mechanisms on your applications? My application does not deploy on Kubernetes, I have no idea why that is and how to fix it? The list goes on and on... After having worked on Kubernetes for several years now and managed teams of developers and architects that had to develop and maintain Kubernetes instances, it became clear for me that something had to change. Companies hire developers to build applications that will run on Kubernetes, but in order to develop applications for Kubernetes, you need to have some solid experience in the domain, making you a rather experienced cloud developer with a undeniable high price tag. Unexperienced developers tend to loose allot of time on understanding Kubernetes in the first place, even more time in learning how to use it properly, leading to very expensive development cycles to get basic applications up and running. Financially, this does not make much sense. If every company had to only hire experienced kubernetes developers to get anything done with it, project costs would rapidly spiral out of control, without mentioning the fact that there are not that many skilled kubernetes experts available in the first place. MDos is an attempt to solve some of those complexity issues for developers and companies, letting them focus on developing applications and not about how to get them running securely on Kubernetes.","title":"Why would you want to use it?"},{"location":"#features","text":"Those can be split into 5 families: Application specific resource configurations Deploy and debug your applications Advanced volume and storage workflows Multi-tenant based segregation OIDC / OAuth2 authentication & Application RBAC Cert-Manager for TLS certificate issuer and secret management","title":"Features"},{"location":"#1-application-specific-resource-configurations","text":"Using the MDos CLI and a unified mdos.yaml application descriptor file, you can build complex Kubernetes deployment scenarios without any knowledge of Kubernetes resource definition types such as Deployments , StatefulSets , Pods , Services , PV & PVCs , VirtualServices , Secrets , ConfigMaps , NetworkPolicies ... (just to name a few) Therefore, build your applications using higher level artefact that will translate to lower level Kubernetes resource definitions based on Kubernetes best practices. Scaffold a new application workspace Scaffold a application component inside your mdos application Add config files & environment variables to your application components Add secret (sensitive) files and environment variables to your application components Expose your application components to other resources within the cluster Configure hostname based ingress rules to allow access to your application components from outside of the cluster Mount various volume types to your application components ...","title":"1. Application specific resource configurations"},{"location":"#2-deploy-and-debug-your-applications","text":"One mdos CLI command to deploy your applications and sync static volumes with your pods Get real-time detailed feedback on your deployments, providing valuable feedback on what might go wrong in order to fix it Get all application component logs, including init container logs in case of a failed deployment for instant debugging Aggregate all application & platform logs in Loki, accessible through a dedicated API (TODO)","title":"2. Deploy and debug your applications"},{"location":"#3-advanced-volume-and-storage-workflows","text":"Synchronize / provision static local data with your application component volumes before they start in Kubernetes Provision shared filesystem volumes for your application components (TODO)","title":"3. Advanced volume and storage workflows"},{"location":"#4-multi-tenant-based-segregation","text":"A tenant will get a Kubernetes namespace as well as a dedicated Keycloak client (for user management) You can create users on the platform and link them to one or more tenants Manage user permissions (RBAC) specifically for each tenant namespace / keycloak client Kubernetes namespaces let you take advantage of network and resource segregation mechanisms for each tenant","title":"4. Multi-tenant based segregation"},{"location":"#5-oidc-oauth2-authentication-application-rbac","text":"Provision OIDC / OAuth2 based Authentication providers to your cluster ready to use Link OIDC / OAuth2 provisioned providers to your application components to protect those resources (no app changes needed) Assign roles to your users specifically on each tenant / keycloak client, allowing you to implement your ACL logic without having to deal with authentication at all","title":"5. OIDC / OAuth2 authentication &amp; Application RBAC"},{"location":"#6-cert-manager-for-tls-certificate-issuer-and-secret-management","text":"Register Cert-Manager Issuers onto your cluster or namespace Generate and manage certificates / secrets from your Issuers","title":"6. Cert-Manager for TLS certificate issuer and secret management"},{"location":"advanced-resources/","text":"Advanced Resources Please note Only applicable for MDos managed cluster deployments Manage Namespaces, Users, Roles and Permissions Tenant Namespaces Namespaces in Kubernetes are used to group resources together. You can manage your namespaces manually like you would on any Kubernetes cluster, but if you create them using the MDos CLI, then it will also create a new Client space in Keycload that is bound to the namespace in order to manage Users and roles for authentication and ACL management. This is the base for leveraging extra features on your cluster such as OIDC authentication, RBAC access control and other tenant segregation mechanisms to secure your cluster tenants. If you have the MDos CLI installed on your machine, then you wont need to install the kubectl CLI to start managing the cluster. You can use the MDos CLI to create your tenants (and there respective kubernetes namespaces), and then create / manage your users and their permissions for those tenant namespaces using the same CLI (more on the Users, roles and permissions in the next section). Those users will then use the MDos CLI to install and configure their respective kubectl CLI according to their roles and permissions (RBAC). Simply create a new tenant / namespace like this: mdos ns create Note By default, only the platform admin can create namespaces. Once you have created other users on the platform, you can give them permissions to create tenant namespaces as well if you wish to delegate tenant management tasks to them. Namespace Users, Roles and Permissions If you created a tenant namespace using the MDos CLI, then you will be able to manage users and user roles for this namespace using Keycloak (authentication is based on OIDC OAuth2). In Keycloak, you create clients and users , then for clients you can create client specific roles . Finally you will assign specific client roles to those users . MDos comes with a system client called mdos that is used to assign global administrative roles to your users. On top of this, every namespace you create using the MDos CLI will create it's own dedicated client in Keycloak. Those namespaces have a few pre-defined roles already available for tenant specific permission management, but then you can then create your own roles inside this client space that you can leverage to implement your ACL layer inside your applications (more on this in the section Securing applications using OIDC providers ). Keycloak client Role name Permissions mdos admin No limitations, can do everything mdos create-namespace Create new clients / namespaces mdos list-namespace List all clients / namespaces mdos delete-namespace Delete a client / namespace mdos create-users Create new users mdos list-users List / read all users mdos delete-users Delete users mdos create-roles Create client roles for any client mdos delete-roles Delete client roles from any client mdos assign-roles Assign client roles for any client and to any user mdos cm-cluster-issuer Create and delete Cert-manager ClusterIssuers mdos oidc-create Can create a new OIDC oauth2 endpoint for applications to use mdos oidc-remove Can delete OIDC oauth2 endpoints Keycloak client Role name Permissions tenant-namespace k8s-write Can deploy / delete / update applications on the client namespace using the Mdos API tenant-namespace k8s-read Can list applications on the client namespace using the Mdos API tenant-namespace admin Create / delete namespace specific client roles. Assign namespace specific client roles to any user. List all users for this client namespace. tenant-namespace -your own role- Create your own custom role names to use within your applications Create a user mdos auth user create Note You will be given the opportunity to assign existing roles to your new user directly after the new user is created. Of course, you can choose not to for now, and use the command mdos auth user add-role to do so at any time. Assign namespace specific roles to this new user mdos auth user add-role ? Do you want to add a role from the Mdos admin client or from a tenant client? ( Use arrow keys ) \u276f Mdos admin client role Tenant client role Here you have the choice between assigning roles from the Keycloak mdos client or from one of your own tenant specific client. Let's choose to add a mdos client role to this ne user. ? Do you want to add a role from the Mdos admin client or from a tenant client? Mdos admin client role ? Select a role to add from this client: ( Use arrow keys ) \u276f create-roles create-users delete-namespace oidc-create assign-roles cm-cluster-issuer delete-users Once you have chosen what role to assign to your user, enter that username to attach the role to: ? Select a role to add from this client: create-namespace ? What username do you wish to add this client role to: my-user-one Add role to user... done Note Refer to the table in the beginning of this chapter for more details on the various roles you can assign to your users. Create namespace specific roles for your applications mdos auth tenant create-role ? Select a Client ID to create a Role for : food-shop ? Enter the client role name to create: edit-recipe Creating Keycloak client role... done Just like we added a mdos client specific role to our new user, you can now assign this new namespace scoped role edit-recipe to your users as well. For more information on how to use those custom roles, see the chapter (more on this in the section Securing applications using OIDC providers . Securing applications using OIDC providers You can protect your applications using OAuth2 OIDC without having to write a single line of code or modify your applications in any way. You have the option of a variety of OIDC providers such as Keycloak, Google, GitHub and others. Secure your application using MDos Keycloak OIDC While you can use various OIDC providers to protect your applications using OIDC authentication, using the integrated Keycloak deployment for your user authentication needs will allow you to also manage your application specific RBAC setup by defining roles and assigning them to your users. MDos uses the open-source solution oauth2-proxy to abstract away the complexity of implementing OAuth2 authentication workflows for your applications. Secure your application using fine grained ACL supported by Keycloak & OIDC Let's start by having a look at how you can leverage Keycloak and OIDC to implement your RBAC rules to your applications. The first step is to create a new oauth2-proxy provider instance for the integrated Keycloak deployment to your target namespace: mdos oidc provider add ? What OIDC target do you want to add to the platform? Keycloak client ? Select a Client ID tenant-one Creating Keycloak client & OIDC provider... done Thats it, you application can now refer to it in order to implement authentication to your application without writing a single line of code. Here is an example that adds OIDC authentication to your specific ingress domain name for an application component: schemaVersion: v1 tenantName: your-tenant-name appName: my-app uuid: XA74S-FXCDI components: - name: secret-app-component image: your-tenant-name/my-app uuid: E5PLU-TQMBD tag: 1 .1.0 services: - name: http ports: - port: 80 ingress: - name: main matchHost: secret.mydomain.com targetPort: 80 trafficType: http oidc: provider: kc-tenant-one hosts: - secret.mydomain.com In this example, we link our new oauth2-proxy kc-tenant-one to our application component secret-app-component , and protect the domain secret.mydomain.com with it. Once this application is deployed and you try to access it on the domain secret.mydomain.com , you will be redirected to the Keycloak login page. Once authenticated through Keycloak, you will gain access to your secret application. Info The domain name you protect has be be configured as an ingress to this application component as well, otherwise there is no access to this component to protect in the first place. But that's not all we can do here, let's go one step further and have a look as of how you can leverage your user sessions and their associated roles using your own ACL / RBAC layer from within your application (creating users and roles, as well as assigning roles to those users is described in the chapter Namespace Users, Roles and Permissions ). Once this user hits your application, the user is already authenticated and we are sure that we have a valid JWT token available in the header of the request under the property named authorization . So all we have to do now is to decode this JWT token using a language specific JWT library (all modern languages have such a library available, usually through a third party library). Once decoded, you will find all keycloak clients (corresponding to the application tenant namespace) this user has permissions for, as well as the specific roles added to this specific user in each respective client space. Simply use this information to allow / disallow fine grained access to the various features of your application: JWT token client roles once decoded resource_access.<CLIENT_NAMESPACE>.roles [ 'role-1' , 'role-2' , ... ] Tip In the near future, it will be possible to specify global access to an application based on user roles directly from within your mdos.yaml configuration file. This will not allow you to do fine grained access control to specific users on specific parts of your application like the example we are showing you here, but il will allow you to restrict global access to applications based on their user roles without having to implement anything on your side. This new feature is currently under development. Secure your application using third party OIDC providers You can also leverage public OIDC providers for your authentication needs such as Google, Github and others. To do so, you will have to configure your external auth provider in order to get your access key, necessary to configure the oauth2-proxy instance dedicated for this external OIDC provider. For more information of how to configure your Google account for instance can be found here . Creating a Google auth based OIDC provider, use the command: mdos oidc provider add -t google and follow the directions. Info As of now, only Google is available through the MDos platform as an external OIDC provider. Github authentication and others will follow soon. Managing your Issuers & TLS Certificates using Cert-Manager Cert-manager is a great extension for Kubernetes, allowing you to generate and manage your domain specific TLS certificates automatically. That said, you still need to understand how to configure it for your needs. The first thing you need is a certificate issuer . Those are used to interact with your Certificate authority and your DNS provider in order to configure the necessary challenges required to obtain your certificates. Certificate Issuers Let's say you purchased the domain name mdos-is-awesome.com . You now need a valid certificate so that you can use your domain name to access your applications. The type of issuer you will have to create depends on the DNS provider you use to manage your newly purchased domain name. Here are a few examples of DNS providers that cert-manager supports directly: Akamai AzureDNS CloudFlare Google Route53 DigitalOcean But others can be configured as well, using external third party webhook instances. Tip For further details about available issuers and how to configure those, please refer to the cert-manager documentation available here So how do you create a new issuer for your new domain name? Issuers are deployed using a simple yaml file. Please note that you only need one issuer per DNS provider account, once you have configured this issuer, you can reference it for every new domain name certificate you wish to create. Let's say your domain name is managed by CloudFlare , in this case you can create a new issuer for your domain name with the following yaml file: issuer.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 apiVersion : v1 kind : Secret metadata : name : cloudflare-api-key-secret type : Opaque stringData : api-key : <YOUR CLOUDFLARE API KEY> --- apiVersion : cert-manager.io/v1 kind : ClusterIssuer metadata : name : my-cloudflare-issuer spec : acme : email : <YOUR LETS-ENCRYPT EMAIL ADDRESS> server : https://acme-v02.api.letsencrypt.org/directory privateKeySecretRef : name : letsencrypt-prod solvers : - dns01 : cloudflare : email : <YOUR CLOUDFLARE EMAIL ADDRESS> apiKeySecretRef : name : cloudflare-api-key-secret key : api-key In this example, you have a Secret that holds your CloudFlare API Key (that you get from your CloudFlare account profile page), and a Issuer . The issuer references a Certificate authority, in this case we use Let's Encrypt to generate the certificate for us (line 14, acme is used here, all we need to do is point to the desired certificate management API endpoint on line 16). On line 21 we specify the DNS solver that is managing our domain name(s). This part will need to be configured to point to the Secret we create in the first block, the one that holds our CloudFlare API Key, and our CloudFlare account email address (line 22). Note Depending on your specific requirements in terms of domain DNS manager and certificate authority, this yaml file will have to be adapted to suit your needs. Again, further details of how you can configure those can be found here You are now ready to deploy this Issuer onto your cluster using the MDos CLI: mdos cm issuer create ? What type of issuer do you wish to create? ClusterIssuer ( Cluster wide ) ? Enter the path to your Issuer YAML file: /Users/mdundek/issuer.yaml INFO : ClusterIssuer name: my-cloudflare-issuer Creating issuer... done Tip Depending on your needs, there are to Issuer types you can choose from: Issuer or ClusterIssuer . Depending on the issuer type, you will be able to create certificates from any tenant namespace (ClusterIssuer), or only for a specific tenant namespace (Issuer). That's it, you are ready to create certificates for this issuer. To list your available issuers, run the command: mdos cm issuer list CERTIFICATE NAME NAMESPACE STATUS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 my-cloudflare-issuer none ( ClusterIssuer ) Ready If your issuer has the status READY , you are good to go to generate some certificates for us. Create new certificates for your applications This part is easy, now that we have a working Issuer , we can go ahead and generate a certificate for one or multiple domain names at once. To do so, execute the command: 1 2 3 4 5 6 7 8 9 mdos cm certificate create ? Select a namespace for which to create a certificate for : my-tenant-namespace ? Enter a name for this certificate: mdos-is-awesome-crt ? Use cert-manager to generate and manage your certificate, or provide the certificate files manually: Use Cert-Manager ? What Cert-Manager issuer would you like to use: my-cloudflare-issuer ( ClusterIssuer ) ? Enter a target domain name ( ex. frontend.mydomain.com or *.mydomain.com ) : mdos-is-awesome.com ? Would you like to add another domain name for this certificate request? No Creating certificate... done On line 6, we selected our Issuer instance we created previously, and on line 7 we can list all domain names (including wild card domains if available) as we need for this certificate. Let's list the available certificates on our cluster: mdos cm certificate list ? Select a namespace for which to create a certificate for : my-tenant-namespace CERTIFICATE NAME ISSUER NAME STATUS MESSAGE \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 mdos-is-awesome-crt my-cloudflare-issuer Ready Certificate is up to date and has not expired TLS SECRET NAME \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 mdos-is-awesome-crt Here you can see that the certificate object is Ready , and the generated kubernetes Secret is available under the same name than the certificate object you just created. That's it, you can now move on to use this new secret in your Ingress-gateways , this will be detailed in the next chapter, so just read on. Managing your Domain specific Ingress-Gateways Ingress gateways are used to instruct Kubernetes on how and what domain names to expose outside of the kubernetes cluster. Is is a cloud native reverse-proxy so to speak that listens for traffic on specific ports and for specific domains. You can configure your certificates on those gateways if you wish to terminate the TLS connection before traffic reaches your application for certain domains, or let the traffic pass through as-is to your target applications, allowing you to terminate the TLS connection in your application directly. Warning When you create a new Ingress Gateway for a specific tenant namespace, it will do nothing on it's own until you deploy an application that configures a ingress rule for it. In other words, if you define an ingress config on one of your application components, then you first need to configure your Ingress gateway to allow this traffic type for your domain. More on this in the next section. So that's for the theory of it. Lets' see how you can create a new Ingress Gateway in your tenant namespace: mdos ingress-gateway add ? Select namespace for which you wish to edit the Ingress Gateway for: my-tenant-namespace ? What type of traffic are you intending to enforce for this config? (Use arrow keys) \u276f HTTP (Listen on port 80, forwards to port 80) HTTPS, pass-through (Listen on port 443, forwards to port 443) HTTPS, terminate TLS (Listen on port 443, forwards to port 80) ... First, you select the tenant namespace for which you want to create a new gateway for. Second, you have to specify what traffic type you wish to configure on that gateway ( HTTP , HTTPS, terminate TLS , or HTTPS, pass-through ). Let's say we choose to create a configuration that will terminate the TLS connection on the gateway itself for a specific domain name. We are not talking about ingress configs yet, first we need to configure our gateway so that it knows that we want to route certain domain names in a specific way. So if I select the option HTTPS, terminate TLS , it will allow us to select amongst all available TLS certificate secrets found in that namespace. ... ? What type of traffic are you intending to enforce for this config? HTTPS, terminate TLS (Listen on port 443, forwards to port 80) ? Enter a target domain name (ex. frontend.mydomain.com): mdos-is-awesome.com ? Would you like to add another domain name host to this Ingress Gateway? No ? What TLS secret holds your certificate and key data for these domains? mdos-is-awesome-crt Creating ingress-gateway server config... done The Ingress Gateway is now configures to allow this type of traffic for your application ingress . You can list your gateway configurations using the MDos CLI: mdos ingress-gateway list ? Select namespace for which you wish to list Ingress Gateways for: my-tenant-namespace TRAFFIC TYPE HOSTS SECRET \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 HTTPS, terminate TLS mdos-is-awesome.com mdos-is-awesome-crt Configure an ingress rule for your application that uses this gateway config Now that we have our ingress gateway configured to allow incoming traffic for our new domain mdos-is-awesome.com on port 443 that terminates the TLS connection on the gateway for us, we can configure this domain name as an ingress in our mdos.yaml application metadata file. We recommend to use the MDos CLI to do this, but you can also do this manually by editing the mdos.yaml file. Let's use the CLI here to configure our ingress. Position your terminal inside your application component directory, and execute the command: mdos generate ingress ? Enter a name for the ingress: my-ingress ? What domain name do you want to use to access your component: mdos-is-awesome.com ? Do you want to match a subpath for this host (fan-out)? No ? What target port should this traffic be redirected to? 80 NOTE: Make sure you have configured your namespace specific \"Ingress Gateway\" to handle this domain name and traffic type (HTTP and/or HTTPS). If your application requires that a dedicated certificate is available inside your POD (versus terminating the TLS connection on the gateway), then specify HTTPS here. ? What type of traffic will this ingress redirect to? http This will update your application mdos.yaml file with the new ingress rule: 1 2 3 4 5 6 7 8 9 10 ... components : - name : comp-1 ... ingress : - name : my-ingress matchHost : mdos-is-awesome.com targetPort : 80 trafficType : http ... Info MDos will automatically identify what Ingress Gateway matches this ingress configuration when you deploy it, and use it to expose your application for that domain. Now what if you wish to terminate a TLS connection directly in your application? Simple, set the trafficType to https , and it will use the Ingress Gateway that is configured to let HTTPS traffic pass through all the way to your application on port 443. You will of course need the certificate key and crt files to terminate this connection inside your application, simply reference the TLS Secret that holds the certificate files from your namespace, and mount it as a volume inside your pod. Here is the mdos.yaml configuration that will allow you to do so: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ... components : - name : comp-1 ... ingress : - name : my-ingress matchHost : mdos-is-awesome.com targetPort : 443 trafficType : https secrets : - name : my-ca type : dir mountPath : /etc/x509/https ref : mdos-is-awesome-crt ... This will mount the files tls.crt and tls.key inside the folder /etc/x509/https on your running containers. You can now use those to terminate your TLS connection. Populate static volume data for your applications Every new volume that is created for your application is completely empty at first! This is how Kubernetes deals with volumes (also known as Persisted Volumes in the Kubernetes world)? So what if I have some data that I would like to put into this volume that my application depends on? Initial database schema & dataset, a static website that serves as a base for my application etc. Often, an empty volume is what you want in a persisted volume, but sometimes your volumes need data to be present at application startup. So what usually happens is that you have to complexify your app with all sorts of init mechanisms that detect an empty volume, and populate it before you can actually start using it. Bringing data to PVCs is difficult! MDos provides an efficient way for dealing with those use-cases. An MDos application project can have volumes declared that contain data you wish to pre-load onto your PODs before your application starts on the cluster. You will simply have to add the flag syncVolume: true to the declared volume inside your application component in your mdos.yaml file, and mdos will automatically sync this volume data to your pod volume before it starts your application component (see Pre-populate volumes in the reference documentation for an example configuration for your mdos.yaml file). Let's have a look at the above example to see in details what actually happens here: Step Description 1 When the user runs the command mdos application deploy , the CLI will look for volumes that are flagged with the attribute syncVolume: true in all application components. 2 The MDos CLI will then initiate a ftp mirror command to synchronize your local volume files with the MDos FTP server 3 Then your application is deployed onto the cluster 4 Before the application actually starts, it will first mirror back your volume data from the MDos FTP server to your application Persisted Volume 5 Once the data is fully synchronized, your application starts up and has access to your pre-loaded files Note All this happens automatically with the command mdos application deploy , you do not need to worry about these steps, nevertheless it is useful for you to understand what is actually happening under the hood.","title":"Advanced Resources"},{"location":"advanced-resources/#advanced-resources","text":"Please note Only applicable for MDos managed cluster deployments","title":"Advanced Resources"},{"location":"advanced-resources/#manage-namespaces-users-roles-and-permissions","text":"","title":"Manage Namespaces, Users, Roles and Permissions"},{"location":"advanced-resources/#tenant-namespaces","text":"Namespaces in Kubernetes are used to group resources together. You can manage your namespaces manually like you would on any Kubernetes cluster, but if you create them using the MDos CLI, then it will also create a new Client space in Keycload that is bound to the namespace in order to manage Users and roles for authentication and ACL management. This is the base for leveraging extra features on your cluster such as OIDC authentication, RBAC access control and other tenant segregation mechanisms to secure your cluster tenants. If you have the MDos CLI installed on your machine, then you wont need to install the kubectl CLI to start managing the cluster. You can use the MDos CLI to create your tenants (and there respective kubernetes namespaces), and then create / manage your users and their permissions for those tenant namespaces using the same CLI (more on the Users, roles and permissions in the next section). Those users will then use the MDos CLI to install and configure their respective kubectl CLI according to their roles and permissions (RBAC). Simply create a new tenant / namespace like this: mdos ns create Note By default, only the platform admin can create namespaces. Once you have created other users on the platform, you can give them permissions to create tenant namespaces as well if you wish to delegate tenant management tasks to them.","title":"Tenant Namespaces"},{"location":"advanced-resources/#namespace-users-roles-and-permissions","text":"If you created a tenant namespace using the MDos CLI, then you will be able to manage users and user roles for this namespace using Keycloak (authentication is based on OIDC OAuth2). In Keycloak, you create clients and users , then for clients you can create client specific roles . Finally you will assign specific client roles to those users . MDos comes with a system client called mdos that is used to assign global administrative roles to your users. On top of this, every namespace you create using the MDos CLI will create it's own dedicated client in Keycloak. Those namespaces have a few pre-defined roles already available for tenant specific permission management, but then you can then create your own roles inside this client space that you can leverage to implement your ACL layer inside your applications (more on this in the section Securing applications using OIDC providers ). Keycloak client Role name Permissions mdos admin No limitations, can do everything mdos create-namespace Create new clients / namespaces mdos list-namespace List all clients / namespaces mdos delete-namespace Delete a client / namespace mdos create-users Create new users mdos list-users List / read all users mdos delete-users Delete users mdos create-roles Create client roles for any client mdos delete-roles Delete client roles from any client mdos assign-roles Assign client roles for any client and to any user mdos cm-cluster-issuer Create and delete Cert-manager ClusterIssuers mdos oidc-create Can create a new OIDC oauth2 endpoint for applications to use mdos oidc-remove Can delete OIDC oauth2 endpoints Keycloak client Role name Permissions tenant-namespace k8s-write Can deploy / delete / update applications on the client namespace using the Mdos API tenant-namespace k8s-read Can list applications on the client namespace using the Mdos API tenant-namespace admin Create / delete namespace specific client roles. Assign namespace specific client roles to any user. List all users for this client namespace. tenant-namespace -your own role- Create your own custom role names to use within your applications","title":"Namespace Users, Roles and Permissions"},{"location":"advanced-resources/#create-a-user","text":"mdos auth user create Note You will be given the opportunity to assign existing roles to your new user directly after the new user is created. Of course, you can choose not to for now, and use the command mdos auth user add-role to do so at any time.","title":" Create a user"},{"location":"advanced-resources/#assign-namespace-specific-roles-to-this-new-user","text":"mdos auth user add-role ? Do you want to add a role from the Mdos admin client or from a tenant client? ( Use arrow keys ) \u276f Mdos admin client role Tenant client role Here you have the choice between assigning roles from the Keycloak mdos client or from one of your own tenant specific client. Let's choose to add a mdos client role to this ne user. ? Do you want to add a role from the Mdos admin client or from a tenant client? Mdos admin client role ? Select a role to add from this client: ( Use arrow keys ) \u276f create-roles create-users delete-namespace oidc-create assign-roles cm-cluster-issuer delete-users Once you have chosen what role to assign to your user, enter that username to attach the role to: ? Select a role to add from this client: create-namespace ? What username do you wish to add this client role to: my-user-one Add role to user... done Note Refer to the table in the beginning of this chapter for more details on the various roles you can assign to your users.","title":" Assign namespace specific roles to this new user"},{"location":"advanced-resources/#create-namespace-specific-roles-for-your-applications","text":"mdos auth tenant create-role ? Select a Client ID to create a Role for : food-shop ? Enter the client role name to create: edit-recipe Creating Keycloak client role... done Just like we added a mdos client specific role to our new user, you can now assign this new namespace scoped role edit-recipe to your users as well. For more information on how to use those custom roles, see the chapter (more on this in the section Securing applications using OIDC providers .","title":" Create namespace specific roles for your applications"},{"location":"advanced-resources/#securing-applications-using-oidc-providers","text":"You can protect your applications using OAuth2 OIDC without having to write a single line of code or modify your applications in any way. You have the option of a variety of OIDC providers such as Keycloak, Google, GitHub and others.","title":"Securing applications using OIDC providers"},{"location":"advanced-resources/#secure-your-application-using-mdos-keycloak-oidc","text":"While you can use various OIDC providers to protect your applications using OIDC authentication, using the integrated Keycloak deployment for your user authentication needs will allow you to also manage your application specific RBAC setup by defining roles and assigning them to your users. MDos uses the open-source solution oauth2-proxy to abstract away the complexity of implementing OAuth2 authentication workflows for your applications.","title":"Secure your application using MDos Keycloak OIDC"},{"location":"advanced-resources/#secure-your-application-using-fine-grained-acl-supported-by-keycloak-oidc","text":"Let's start by having a look at how you can leverage Keycloak and OIDC to implement your RBAC rules to your applications. The first step is to create a new oauth2-proxy provider instance for the integrated Keycloak deployment to your target namespace: mdos oidc provider add ? What OIDC target do you want to add to the platform? Keycloak client ? Select a Client ID tenant-one Creating Keycloak client & OIDC provider... done Thats it, you application can now refer to it in order to implement authentication to your application without writing a single line of code. Here is an example that adds OIDC authentication to your specific ingress domain name for an application component: schemaVersion: v1 tenantName: your-tenant-name appName: my-app uuid: XA74S-FXCDI components: - name: secret-app-component image: your-tenant-name/my-app uuid: E5PLU-TQMBD tag: 1 .1.0 services: - name: http ports: - port: 80 ingress: - name: main matchHost: secret.mydomain.com targetPort: 80 trafficType: http oidc: provider: kc-tenant-one hosts: - secret.mydomain.com In this example, we link our new oauth2-proxy kc-tenant-one to our application component secret-app-component , and protect the domain secret.mydomain.com with it. Once this application is deployed and you try to access it on the domain secret.mydomain.com , you will be redirected to the Keycloak login page. Once authenticated through Keycloak, you will gain access to your secret application. Info The domain name you protect has be be configured as an ingress to this application component as well, otherwise there is no access to this component to protect in the first place. But that's not all we can do here, let's go one step further and have a look as of how you can leverage your user sessions and their associated roles using your own ACL / RBAC layer from within your application (creating users and roles, as well as assigning roles to those users is described in the chapter Namespace Users, Roles and Permissions ). Once this user hits your application, the user is already authenticated and we are sure that we have a valid JWT token available in the header of the request under the property named authorization . So all we have to do now is to decode this JWT token using a language specific JWT library (all modern languages have such a library available, usually through a third party library). Once decoded, you will find all keycloak clients (corresponding to the application tenant namespace) this user has permissions for, as well as the specific roles added to this specific user in each respective client space. Simply use this information to allow / disallow fine grained access to the various features of your application: JWT token client roles once decoded resource_access.<CLIENT_NAMESPACE>.roles [ 'role-1' , 'role-2' , ... ] Tip In the near future, it will be possible to specify global access to an application based on user roles directly from within your mdos.yaml configuration file. This will not allow you to do fine grained access control to specific users on specific parts of your application like the example we are showing you here, but il will allow you to restrict global access to applications based on their user roles without having to implement anything on your side. This new feature is currently under development.","title":"Secure your application using fine grained ACL supported by Keycloak &amp; OIDC"},{"location":"advanced-resources/#secure-your-application-using-third-party-oidc-providers","text":"You can also leverage public OIDC providers for your authentication needs such as Google, Github and others. To do so, you will have to configure your external auth provider in order to get your access key, necessary to configure the oauth2-proxy instance dedicated for this external OIDC provider. For more information of how to configure your Google account for instance can be found here . Creating a Google auth based OIDC provider, use the command: mdos oidc provider add -t google and follow the directions. Info As of now, only Google is available through the MDos platform as an external OIDC provider. Github authentication and others will follow soon.","title":"Secure your application using third party OIDC providers"},{"location":"advanced-resources/#managing-your-issuers-tls-certificates-using-cert-manager","text":"Cert-manager is a great extension for Kubernetes, allowing you to generate and manage your domain specific TLS certificates automatically. That said, you still need to understand how to configure it for your needs. The first thing you need is a certificate issuer . Those are used to interact with your Certificate authority and your DNS provider in order to configure the necessary challenges required to obtain your certificates.","title":"Managing your Issuers &amp; TLS Certificates using Cert-Manager"},{"location":"advanced-resources/#certificate-issuers","text":"Let's say you purchased the domain name mdos-is-awesome.com . You now need a valid certificate so that you can use your domain name to access your applications. The type of issuer you will have to create depends on the DNS provider you use to manage your newly purchased domain name. Here are a few examples of DNS providers that cert-manager supports directly: Akamai AzureDNS CloudFlare Google Route53 DigitalOcean But others can be configured as well, using external third party webhook instances. Tip For further details about available issuers and how to configure those, please refer to the cert-manager documentation available here","title":"Certificate Issuers"},{"location":"advanced-resources/#so-how-do-you-create-a-new-issuer-for-your-new-domain-name","text":"Issuers are deployed using a simple yaml file. Please note that you only need one issuer per DNS provider account, once you have configured this issuer, you can reference it for every new domain name certificate you wish to create. Let's say your domain name is managed by CloudFlare , in this case you can create a new issuer for your domain name with the following yaml file: issuer.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 apiVersion : v1 kind : Secret metadata : name : cloudflare-api-key-secret type : Opaque stringData : api-key : <YOUR CLOUDFLARE API KEY> --- apiVersion : cert-manager.io/v1 kind : ClusterIssuer metadata : name : my-cloudflare-issuer spec : acme : email : <YOUR LETS-ENCRYPT EMAIL ADDRESS> server : https://acme-v02.api.letsencrypt.org/directory privateKeySecretRef : name : letsencrypt-prod solvers : - dns01 : cloudflare : email : <YOUR CLOUDFLARE EMAIL ADDRESS> apiKeySecretRef : name : cloudflare-api-key-secret key : api-key In this example, you have a Secret that holds your CloudFlare API Key (that you get from your CloudFlare account profile page), and a Issuer . The issuer references a Certificate authority, in this case we use Let's Encrypt to generate the certificate for us (line 14, acme is used here, all we need to do is point to the desired certificate management API endpoint on line 16). On line 21 we specify the DNS solver that is managing our domain name(s). This part will need to be configured to point to the Secret we create in the first block, the one that holds our CloudFlare API Key, and our CloudFlare account email address (line 22). Note Depending on your specific requirements in terms of domain DNS manager and certificate authority, this yaml file will have to be adapted to suit your needs. Again, further details of how you can configure those can be found here You are now ready to deploy this Issuer onto your cluster using the MDos CLI: mdos cm issuer create ? What type of issuer do you wish to create? ClusterIssuer ( Cluster wide ) ? Enter the path to your Issuer YAML file: /Users/mdundek/issuer.yaml INFO : ClusterIssuer name: my-cloudflare-issuer Creating issuer... done Tip Depending on your needs, there are to Issuer types you can choose from: Issuer or ClusterIssuer . Depending on the issuer type, you will be able to create certificates from any tenant namespace (ClusterIssuer), or only for a specific tenant namespace (Issuer). That's it, you are ready to create certificates for this issuer. To list your available issuers, run the command: mdos cm issuer list CERTIFICATE NAME NAMESPACE STATUS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 my-cloudflare-issuer none ( ClusterIssuer ) Ready If your issuer has the status READY , you are good to go to generate some certificates for us.","title":"So how do you create a new issuer for your new domain name?"},{"location":"advanced-resources/#create-new-certificates-for-your-applications","text":"This part is easy, now that we have a working Issuer , we can go ahead and generate a certificate for one or multiple domain names at once. To do so, execute the command: 1 2 3 4 5 6 7 8 9 mdos cm certificate create ? Select a namespace for which to create a certificate for : my-tenant-namespace ? Enter a name for this certificate: mdos-is-awesome-crt ? Use cert-manager to generate and manage your certificate, or provide the certificate files manually: Use Cert-Manager ? What Cert-Manager issuer would you like to use: my-cloudflare-issuer ( ClusterIssuer ) ? Enter a target domain name ( ex. frontend.mydomain.com or *.mydomain.com ) : mdos-is-awesome.com ? Would you like to add another domain name for this certificate request? No Creating certificate... done On line 6, we selected our Issuer instance we created previously, and on line 7 we can list all domain names (including wild card domains if available) as we need for this certificate. Let's list the available certificates on our cluster: mdos cm certificate list ? Select a namespace for which to create a certificate for : my-tenant-namespace CERTIFICATE NAME ISSUER NAME STATUS MESSAGE \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 mdos-is-awesome-crt my-cloudflare-issuer Ready Certificate is up to date and has not expired TLS SECRET NAME \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 mdos-is-awesome-crt Here you can see that the certificate object is Ready , and the generated kubernetes Secret is available under the same name than the certificate object you just created. That's it, you can now move on to use this new secret in your Ingress-gateways , this will be detailed in the next chapter, so just read on.","title":"Create new certificates for your applications"},{"location":"advanced-resources/#managing-your-domain-specific-ingress-gateways","text":"Ingress gateways are used to instruct Kubernetes on how and what domain names to expose outside of the kubernetes cluster. Is is a cloud native reverse-proxy so to speak that listens for traffic on specific ports and for specific domains. You can configure your certificates on those gateways if you wish to terminate the TLS connection before traffic reaches your application for certain domains, or let the traffic pass through as-is to your target applications, allowing you to terminate the TLS connection in your application directly. Warning When you create a new Ingress Gateway for a specific tenant namespace, it will do nothing on it's own until you deploy an application that configures a ingress rule for it. In other words, if you define an ingress config on one of your application components, then you first need to configure your Ingress gateway to allow this traffic type for your domain. More on this in the next section. So that's for the theory of it. Lets' see how you can create a new Ingress Gateway in your tenant namespace: mdos ingress-gateway add ? Select namespace for which you wish to edit the Ingress Gateway for: my-tenant-namespace ? What type of traffic are you intending to enforce for this config? (Use arrow keys) \u276f HTTP (Listen on port 80, forwards to port 80) HTTPS, pass-through (Listen on port 443, forwards to port 443) HTTPS, terminate TLS (Listen on port 443, forwards to port 80) ... First, you select the tenant namespace for which you want to create a new gateway for. Second, you have to specify what traffic type you wish to configure on that gateway ( HTTP , HTTPS, terminate TLS , or HTTPS, pass-through ). Let's say we choose to create a configuration that will terminate the TLS connection on the gateway itself for a specific domain name. We are not talking about ingress configs yet, first we need to configure our gateway so that it knows that we want to route certain domain names in a specific way. So if I select the option HTTPS, terminate TLS , it will allow us to select amongst all available TLS certificate secrets found in that namespace. ... ? What type of traffic are you intending to enforce for this config? HTTPS, terminate TLS (Listen on port 443, forwards to port 80) ? Enter a target domain name (ex. frontend.mydomain.com): mdos-is-awesome.com ? Would you like to add another domain name host to this Ingress Gateway? No ? What TLS secret holds your certificate and key data for these domains? mdos-is-awesome-crt Creating ingress-gateway server config... done The Ingress Gateway is now configures to allow this type of traffic for your application ingress . You can list your gateway configurations using the MDos CLI: mdos ingress-gateway list ? Select namespace for which you wish to list Ingress Gateways for: my-tenant-namespace TRAFFIC TYPE HOSTS SECRET \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 HTTPS, terminate TLS mdos-is-awesome.com mdos-is-awesome-crt","title":"Managing your Domain specific Ingress-Gateways"},{"location":"advanced-resources/#configure-an-ingress-rule-for-your-application-that-uses-this-gateway-config","text":"Now that we have our ingress gateway configured to allow incoming traffic for our new domain mdos-is-awesome.com on port 443 that terminates the TLS connection on the gateway for us, we can configure this domain name as an ingress in our mdos.yaml application metadata file. We recommend to use the MDos CLI to do this, but you can also do this manually by editing the mdos.yaml file. Let's use the CLI here to configure our ingress. Position your terminal inside your application component directory, and execute the command: mdos generate ingress ? Enter a name for the ingress: my-ingress ? What domain name do you want to use to access your component: mdos-is-awesome.com ? Do you want to match a subpath for this host (fan-out)? No ? What target port should this traffic be redirected to? 80 NOTE: Make sure you have configured your namespace specific \"Ingress Gateway\" to handle this domain name and traffic type (HTTP and/or HTTPS). If your application requires that a dedicated certificate is available inside your POD (versus terminating the TLS connection on the gateway), then specify HTTPS here. ? What type of traffic will this ingress redirect to? http This will update your application mdos.yaml file with the new ingress rule: 1 2 3 4 5 6 7 8 9 10 ... components : - name : comp-1 ... ingress : - name : my-ingress matchHost : mdos-is-awesome.com targetPort : 80 trafficType : http ... Info MDos will automatically identify what Ingress Gateway matches this ingress configuration when you deploy it, and use it to expose your application for that domain. Now what if you wish to terminate a TLS connection directly in your application? Simple, set the trafficType to https , and it will use the Ingress Gateway that is configured to let HTTPS traffic pass through all the way to your application on port 443. You will of course need the certificate key and crt files to terminate this connection inside your application, simply reference the TLS Secret that holds the certificate files from your namespace, and mount it as a volume inside your pod. Here is the mdos.yaml configuration that will allow you to do so: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ... components : - name : comp-1 ... ingress : - name : my-ingress matchHost : mdos-is-awesome.com targetPort : 443 trafficType : https secrets : - name : my-ca type : dir mountPath : /etc/x509/https ref : mdos-is-awesome-crt ... This will mount the files tls.crt and tls.key inside the folder /etc/x509/https on your running containers. You can now use those to terminate your TLS connection.","title":"Configure an ingress rule for your application that uses this gateway config"},{"location":"advanced-resources/#populate-static-volume-data-for-your-applications","text":"Every new volume that is created for your application is completely empty at first! This is how Kubernetes deals with volumes (also known as Persisted Volumes in the Kubernetes world)? So what if I have some data that I would like to put into this volume that my application depends on? Initial database schema & dataset, a static website that serves as a base for my application etc. Often, an empty volume is what you want in a persisted volume, but sometimes your volumes need data to be present at application startup. So what usually happens is that you have to complexify your app with all sorts of init mechanisms that detect an empty volume, and populate it before you can actually start using it. Bringing data to PVCs is difficult! MDos provides an efficient way for dealing with those use-cases. An MDos application project can have volumes declared that contain data you wish to pre-load onto your PODs before your application starts on the cluster. You will simply have to add the flag syncVolume: true to the declared volume inside your application component in your mdos.yaml file, and mdos will automatically sync this volume data to your pod volume before it starts your application component (see Pre-populate volumes in the reference documentation for an example configuration for your mdos.yaml file). Let's have a look at the above example to see in details what actually happens here: Step Description 1 When the user runs the command mdos application deploy , the CLI will look for volumes that are flagged with the attribute syncVolume: true in all application components. 2 The MDos CLI will then initiate a ftp mirror command to synchronize your local volume files with the MDos FTP server 3 Then your application is deployed onto the cluster 4 Before the application actually starts, it will first mirror back your volume data from the MDos FTP server to your application Persisted Volume 5 Once the data is fully synchronized, your application starts up and has access to your pre-loaded files Note All this happens automatically with the command mdos application deploy , you do not need to worry about these steps, nevertheless it is useful for you to understand what is actually happening under the hood.","title":"Populate static volume data for your applications"},{"location":"getting-started/","text":"Getting Started We will build a similar hello world example application now, but to keep thinks simple, we will not deploy a backend component along with the frontend component, and not work with volumes yet. Those will be subjects for later on. Choose according to your MDos platform deployment type There are two ways to install the MDos Platform: MDos managed cluster mode MDos Framework only mode This getting started section has an example for both MDos deployment types 1. MDos managed cluster: \"Hello World\" example Configure your CLI to point to a MDos platform API host Before we can start using the mdos CLI, we need to tell it what MDos API server to talk to. Self signed certificates and domain names If you installed the platform using a self-signed certificate without any valid domain names configured, then you will have to ensure that all required platform hostname are configured on your local machine hosts file before you proceed. In Linux and Mac OSX, your can configure those in your /etc/hosts file. In Windows, this file is located under c:\\Windows\\System32\\Drivers\\etc\\hosts . For more information, please refer to the chapter Special notes about self-signed certificates without a resolvable DNS name To configure the target MDos platform API server endpoint with your CLI, use the following command: mdos configure api-endpoint https://mdos-api.mydomain.com Note Replace mydomain.com with your actual root domain name used during the platform installation procedure. You are now ready to start using the platform. Create a tenant namespace In Kubernetes, namespaces are used to group assets together so that they can be properly administered & run in their own scoped context. In MDos, we assign a dedicated namespace to each tenant on the platform. Applications belong to a tenant namespace, without the namespace we can not deploy our application. To create a new tenant namespace called a-team , run the following command: mdos namespace create WARN : Your current token has expired or is invalid. You need to re-authenticate ? Please enter your username: admin-username ? Please enter your password: [hidden] ? Enter a namespace name to create: a-team Creating namespace... done Authentication If this is the first time you interact with the platform (or if your JWT token has expired like in the example above), you will be asked to authenticate yourself first. In our case, we did not add any platform users yet, so we will simply use the admin user account that was used during the platform installation procedure (in this example, the admin username is called admin-username ). If you already have your own user account on the platform, and you have sufficient permissions to create new tenant namespaces and deploy applications, then please go ahead and use this one instead. When using MDos in it's managed cluster mode, what happened on the platform side when you create a namespace using the MDos CLI? Here are some high level details: Create a new Client in Keycloak, required to manage users that will interact with this namespace Create available default roles for this Keycloak client / namespace ( admin , k8s-write , k8s-read , ftp-write , registry-pull , registry-push ) Create namespace in Kubernetes Create namespace roles so that we can apply RBAC permissions to users Configure service account / credentials in Keycloak for ftpd and registry access for this namespace Note Details about these concepts are out of scope in this chapter Create a new application Let's create a new application project using the mdos CLI command: mdos generate application ? Enter a application name: hello-world ? Enter a tenant name that this application belongs to: a-team This will create a new folder with the mdos.yaml configuration file in it. We are now ready to create application components. Create a new application component Inside your application project folder, run the following command: cd hello-world mdos generate component ? Enter a application component name: hello-world-server The CLI will ask you a couple of things about some base configuration parameters. This will create a new component folder with an empty Dockerfile for you to use, as well as update the mdos.yaml file referencing the component as part of the overall application project along with it's configuration parameters. You can now go ahead and implement your hello-world-server application component. Let's do just that. We will create a basic NodeJS HTTP server for this demonstration that will return \"hello world\" when invoked. Create a new file: hello-world/hello-world-server/index.js index.js 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 const http = require ( 'http' ); // Loads the http module http . createServer (( request , response ) => { // 1. Tell the browser everything is OK (Status code 200), and the data is in plain text response . writeHead ( 200 , { 'Content-Type' : 'text/plain' }); // 2. Write the announced text to the body of the page response . write ( 'Hello, World!\\n' ); // 3. Tell the server that all of the response headers and body have been sent response . end (); }). listen ( 8080 ); // 4. Tells the server what port to be on Last but not least, we need to populate our component Dockerfile so that we can build our container image during deployments. Open the Dockerfile that is inside the hello-world-server folder and set it's content to the following: Dockerfile 1 2 3 4 5 6 7 8 9 10 FROM node:16 # Create app directory WORKDIR /usr/src/app # Bundle app source COPY ./server.js . EXPOSE 8080 CMD [ \"node\" , \"server.js\" ] Ok, we have an application ready to use now. Next, we need to tell our mdos application that we want to expose port 8080 , and set up an ingress config to expose it outside of the cluster using the hostname hello-world.mydomain.com . Custom domain names As of now, MDos uses the platform wildcard domain name that was configured during the installation of the platform in order to expose any application you deploy on it. You can of course add other domain names for your various applications if you like, to do so you will have to create a new ingress-gateway configuration in your namespace, but this is out of scope in this example. Let's start with exposing port 8080 for our application component, which can be done with a kubernetes service . Move into the hello-world-server component folder and execute the following command: mdos generate service ? Enter a name for the service to add a port to: http ? Specify a port number on which your application needs to be accessible on: 8080 And finally, the ingress so that we have a hostname configured to access this application: mdos generate ingress ? Enter a name for the ingress: http-ingress ? What hostname do you want to use to access your component port: hello-world.mydomain.com ? Do you want to match a subpath for this host? No ? What target port should this traffic be redirected to? 8080 ? What type of traffic will this ingress handle? http Note Again, replace mydomain.com with whatever domain you configured during the platform installation. That's it, this is what your project file structure should look like now: Project structure hello-world \u251c\u2500\u2500 hello-world-server \u2502 \u251c\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 server.js \u251c\u2500\u2500 mdos.yaml \u2514\u2500\u2500 volumes \u2514\u2500\u2500 README.md Let's have a look at the generated code in the mdos.yaml file: mdos.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 schemaVersion : v1 tenantName : a-team appName : hello-world uuid : mvx10-x2wip components : - name : hello-world-server image : hello-world uuid : qx8su-jwqvi tag : 0.0.1 services : - name : http ports : - port : 8080 ingress : - name : http-ingress matchHost : hello-world.mydomain.com targetPort : 8080 trafficType : http Info All application configuration features will live inside this yaml file, even for the most advanced use-cases and config needs, everything will be here. No need to get dirty with low level kubernetes assets to make it all happen, the platform will translate it all into the proper artefact for you. To learn more about everything that you can configure for your deployments in this yaml file, please check out the MDos application reference documentation Deploy your hello-world application on the cluster Note Since this is a basic example, we will skip user management, authentication or any other advanced topics for now. Since we authenticated with the MDos admin user account, we can deploy onto this namespace without creating / assigning users & permissions for this namespace. Move into the hello-world application and execute the command: mdos application deploy Synching volumes... done To push your images to the mdos registry, you need to provide your mdos username and password first ? Username: admin-username ? Password: ******** Building application image registry.mydomain.com/a-team/hello-world:0.0.1... done Pushing application image registry.mydomain.com/a-team/hello-world:0.0.1... done Deploying application... scheduled Pod: hello-world-server Phase: Running Container: hello-world-hello-world-server State: running Details: n/a SUCCESS : Application deployed That's it, your application should now be accessible on the following domain: https://hello-world.mydomain.com Next steps Please have a look at the chapter MDos application reference documentation for a complete list of what you can configure in the mdos.yaml file, as well as the chapter Advanced Resources to find out how to maximize usage of the platform for more advanced use-cases and features. 2. MDos framework only: \"Hello World\" example Configure your CLI to point to a MDos platform API host Before we can start using the mdos CLI, we need to tell it what MDos API server to talk to. To configure the target MDos platform API server endpoint with your CLI, use the following command: mdos configure api-endpoint https://mdos-api.mydomain.com Note If you installed the MDos Framework platform using the mdos CLI onto your cluster from the same machine than the one you are doing this tutorial from, then you can skip this step since the CLI is already configured. Otherwise, replace the endpoint URL https://mdos-api.mydomain.com with the actual URL you configured to access the MDos API server You are now ready to start using the platform. Create a tenant namespace In Kubernetes, namespaces are used to group assets together so that they can be properly administered & run in their own scoped context. In MDos, we assign a dedicated namespace to each tenant on the platform. Applications belong to a tenant namespace, without the namespace we can not deploy our application. To create a new tenant namespace called a-team , run the following command: mdos namespace create ? Enter a namespace name to create: a-team Creating namespace... done Create a new application Let's create a new application project using the mdos CLI command: mdos generate application ? Enter a application name: hello-world ? Enter a tenant name that this application belongs to: a-team This will create a new folder with the mdos.yaml configuration file in it. We are now ready to create application components. Create a new application component Inside your application project folder, run the following command: cd hello-world mdos generate component ? Enter a application component name: hello-world-server ? What network policy do you want to apply to this component: private (No one can talk to this component) ? Is the component image accessible publicly? Yes ? Does your target registry require authentication to pull images? No Private / Public Registries In MDos framework only mode, there is no private registry available with the platform. Therefore the CLI will ask you a couple of extra questions in order to specify a potential private registry of your own. If that registry requires you to authenticate with it in order to pull & push images from / to the registry, you will have the possibility to specify a secret reference name that holds those credentials as well. This will create a new component folder with an empty Dockerfile for you to use, as well as update the mdos.yaml file referencing the component as part of the overall application project along with it's configuration parameters. You can now go ahead and implement your hello-world-server application component. Let's do just that. We will create a basic NodeJS HTTP server for this demonstration that will return \"hello world\" when invoked. Create a new file: hello-world/hello-world-server/index.js index.js 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 const http = require ( 'http' ); // Loads the http module http . createServer (( request , response ) => { // 1. Tell the browser everything is OK (Status code 200), and the data is in plain text response . writeHead ( 200 , { 'Content-Type' : 'text/plain' }); // 2. Write the announced text to the body of the page response . write ( 'Hello, World!\\n' ); // 3. Tell the server that all of the response headers and body have been sent response . end (); }). listen ( 8080 ); // 4. Tells the server what port to be on Last but not least, we need to populate our component Dockerfile so that we can build our container image during deployments. Open the Dockerfile that is inside the hello-world-server folder and set it's content to the following: Dockerfile 1 2 3 4 5 6 7 8 9 10 FROM node:16 # Create app directory WORKDIR /usr/src/app # Bundle app source COPY ./index.js . EXPOSE 8080 CMD [ \"node\" , \"index.js\" ] Ok, we have an application ready to use now. Next, we need to tell our mdos application that we want to expose port 8080 , and set up an ingress config to expose it outside of the cluster using the hostname hello-world.mydomain.com . Let's start with exposing port 8080 for our application component, which can be done with a kubernetes service . Move into the hello-world-server component folder and execute the following command: mdos generate service ? Enter a name for the service to add a port to: http ? Specify a port number on which your application needs to be accessible on: 8080 And finally, the ingress so that we have a hostname configured to access this application: mdos generate ingress ? Enter a name for the ingress: http-ingress ? What hostname do you want to use to access your component port: hello-world.mydomain.com ? Do you want to match a subpath for this host? No ? What target port should this traffic be redirected to? 8080 ? What type of traffic will this ingress handle? http Note on domain name and DNS resolution It is up to you to make sure that the domain name you choose is resolved by your DNS configuration to point to the Kubernetes cluster IP address. the ingress config will take care of redirecting the traffic to your application component. That's it, this is what your project file structure should look like now: Project structure hello-world \u251c\u2500\u2500 hello-world-server \u2502 \u251c\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 server.js \u2514\u2500\u2500 mdos.yaml Let's have a look at the generated code in the mdos.yaml file: mdos.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 schemaVersion : v1 tenantName : a-team appName : hello-world uuid : mvx10-x2wip components : - name : hello-world-server image : hello-world uuid : qx8su-jwqvi tag : 0.0.1 services : - name : http ports : - port : 8080 ingress : - name : http-ingress matchHost : hello-world.mydomain.com targetPort : 8080 trafficType : HTTP Note All application configuration features will live inside this yaml file, even for the most advanced use-cases and config needs, everything will be here. No need to get dirty with low level kubernetes assets to make it all happen, the platform will translate it all into the proper artefact for you. To learn more about everything that you can configure for your deployments in this yaml file, please check out the MDos application reference documentation Deploy your hello-world application on the cluster Move into the hello-world application and execute the command: mdos application deploy Synching volumes... done To push your images to your registry, you need to provide your docker hub username and password first ? Username: foobar ? Password: ******** Building application image hello-world:0.0.1... done Pushing application image hello-world:0.0.1... done Deploying application... scheduled Pod: hello-world-server Phase: Running Container: hello-world-hello-world-server State: running Details: n/a SUCCESS : Application deployed That's it, your application should now be accessible on the following domain: https://hello-world.mydomain.com Next steps Please have a look at the chapter MDos application reference documentation for a complete list of what you can configure in the mdos.yaml file.","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"We will build a similar hello world example application now, but to keep thinks simple, we will not deploy a backend component along with the frontend component, and not work with volumes yet. Those will be subjects for later on. Choose according to your MDos platform deployment type There are two ways to install the MDos Platform: MDos managed cluster mode MDos Framework only mode This getting started section has an example for both MDos deployment types","title":"Getting Started"},{"location":"getting-started/#1-mdos-managed-cluster-hello-world-example","text":"","title":"1. MDos managed cluster: \"Hello World\" example"},{"location":"getting-started/#configure-your-cli-to-point-to-a-mdos-platform-api-host","text":"Before we can start using the mdos CLI, we need to tell it what MDos API server to talk to. Self signed certificates and domain names If you installed the platform using a self-signed certificate without any valid domain names configured, then you will have to ensure that all required platform hostname are configured on your local machine hosts file before you proceed. In Linux and Mac OSX, your can configure those in your /etc/hosts file. In Windows, this file is located under c:\\Windows\\System32\\Drivers\\etc\\hosts . For more information, please refer to the chapter Special notes about self-signed certificates without a resolvable DNS name To configure the target MDos platform API server endpoint with your CLI, use the following command: mdos configure api-endpoint https://mdos-api.mydomain.com Note Replace mydomain.com with your actual root domain name used during the platform installation procedure. You are now ready to start using the platform.","title":"Configure your CLI to point to a MDos platform API host"},{"location":"getting-started/#create-a-tenant-namespace","text":"In Kubernetes, namespaces are used to group assets together so that they can be properly administered & run in their own scoped context. In MDos, we assign a dedicated namespace to each tenant on the platform. Applications belong to a tenant namespace, without the namespace we can not deploy our application. To create a new tenant namespace called a-team , run the following command: mdos namespace create WARN : Your current token has expired or is invalid. You need to re-authenticate ? Please enter your username: admin-username ? Please enter your password: [hidden] ? Enter a namespace name to create: a-team Creating namespace... done Authentication If this is the first time you interact with the platform (or if your JWT token has expired like in the example above), you will be asked to authenticate yourself first. In our case, we did not add any platform users yet, so we will simply use the admin user account that was used during the platform installation procedure (in this example, the admin username is called admin-username ). If you already have your own user account on the platform, and you have sufficient permissions to create new tenant namespaces and deploy applications, then please go ahead and use this one instead. When using MDos in it's managed cluster mode, what happened on the platform side when you create a namespace using the MDos CLI? Here are some high level details: Create a new Client in Keycloak, required to manage users that will interact with this namespace Create available default roles for this Keycloak client / namespace ( admin , k8s-write , k8s-read , ftp-write , registry-pull , registry-push ) Create namespace in Kubernetes Create namespace roles so that we can apply RBAC permissions to users Configure service account / credentials in Keycloak for ftpd and registry access for this namespace Note Details about these concepts are out of scope in this chapter","title":"Create a tenant namespace"},{"location":"getting-started/#create-a-new-application","text":"Let's create a new application project using the mdos CLI command: mdos generate application ? Enter a application name: hello-world ? Enter a tenant name that this application belongs to: a-team This will create a new folder with the mdos.yaml configuration file in it. We are now ready to create application components.","title":"Create a new application"},{"location":"getting-started/#create-a-new-application-component","text":"Inside your application project folder, run the following command: cd hello-world mdos generate component ? Enter a application component name: hello-world-server The CLI will ask you a couple of things about some base configuration parameters. This will create a new component folder with an empty Dockerfile for you to use, as well as update the mdos.yaml file referencing the component as part of the overall application project along with it's configuration parameters. You can now go ahead and implement your hello-world-server application component. Let's do just that. We will create a basic NodeJS HTTP server for this demonstration that will return \"hello world\" when invoked. Create a new file: hello-world/hello-world-server/index.js index.js 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 const http = require ( 'http' ); // Loads the http module http . createServer (( request , response ) => { // 1. Tell the browser everything is OK (Status code 200), and the data is in plain text response . writeHead ( 200 , { 'Content-Type' : 'text/plain' }); // 2. Write the announced text to the body of the page response . write ( 'Hello, World!\\n' ); // 3. Tell the server that all of the response headers and body have been sent response . end (); }). listen ( 8080 ); // 4. Tells the server what port to be on Last but not least, we need to populate our component Dockerfile so that we can build our container image during deployments. Open the Dockerfile that is inside the hello-world-server folder and set it's content to the following: Dockerfile 1 2 3 4 5 6 7 8 9 10 FROM node:16 # Create app directory WORKDIR /usr/src/app # Bundle app source COPY ./server.js . EXPOSE 8080 CMD [ \"node\" , \"server.js\" ] Ok, we have an application ready to use now. Next, we need to tell our mdos application that we want to expose port 8080 , and set up an ingress config to expose it outside of the cluster using the hostname hello-world.mydomain.com . Custom domain names As of now, MDos uses the platform wildcard domain name that was configured during the installation of the platform in order to expose any application you deploy on it. You can of course add other domain names for your various applications if you like, to do so you will have to create a new ingress-gateway configuration in your namespace, but this is out of scope in this example. Let's start with exposing port 8080 for our application component, which can be done with a kubernetes service . Move into the hello-world-server component folder and execute the following command: mdos generate service ? Enter a name for the service to add a port to: http ? Specify a port number on which your application needs to be accessible on: 8080 And finally, the ingress so that we have a hostname configured to access this application: mdos generate ingress ? Enter a name for the ingress: http-ingress ? What hostname do you want to use to access your component port: hello-world.mydomain.com ? Do you want to match a subpath for this host? No ? What target port should this traffic be redirected to? 8080 ? What type of traffic will this ingress handle? http Note Again, replace mydomain.com with whatever domain you configured during the platform installation. That's it, this is what your project file structure should look like now: Project structure hello-world \u251c\u2500\u2500 hello-world-server \u2502 \u251c\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 server.js \u251c\u2500\u2500 mdos.yaml \u2514\u2500\u2500 volumes \u2514\u2500\u2500 README.md Let's have a look at the generated code in the mdos.yaml file: mdos.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 schemaVersion : v1 tenantName : a-team appName : hello-world uuid : mvx10-x2wip components : - name : hello-world-server image : hello-world uuid : qx8su-jwqvi tag : 0.0.1 services : - name : http ports : - port : 8080 ingress : - name : http-ingress matchHost : hello-world.mydomain.com targetPort : 8080 trafficType : http Info All application configuration features will live inside this yaml file, even for the most advanced use-cases and config needs, everything will be here. No need to get dirty with low level kubernetes assets to make it all happen, the platform will translate it all into the proper artefact for you. To learn more about everything that you can configure for your deployments in this yaml file, please check out the MDos application reference documentation","title":"Create a new application component"},{"location":"getting-started/#deploy-your-hello-world-application-on-the-cluster","text":"Note Since this is a basic example, we will skip user management, authentication or any other advanced topics for now. Since we authenticated with the MDos admin user account, we can deploy onto this namespace without creating / assigning users & permissions for this namespace. Move into the hello-world application and execute the command: mdos application deploy Synching volumes... done To push your images to the mdos registry, you need to provide your mdos username and password first ? Username: admin-username ? Password: ******** Building application image registry.mydomain.com/a-team/hello-world:0.0.1... done Pushing application image registry.mydomain.com/a-team/hello-world:0.0.1... done Deploying application... scheduled Pod: hello-world-server Phase: Running Container: hello-world-hello-world-server State: running Details: n/a SUCCESS : Application deployed That's it, your application should now be accessible on the following domain: https://hello-world.mydomain.com Next steps Please have a look at the chapter MDos application reference documentation for a complete list of what you can configure in the mdos.yaml file, as well as the chapter Advanced Resources to find out how to maximize usage of the platform for more advanced use-cases and features.","title":"Deploy your hello-world application on the cluster"},{"location":"getting-started/#2-mdos-framework-only-hello-world-example","text":"","title":"2. MDos framework only: \"Hello World\" example"},{"location":"getting-started/#configure-your-cli-to-point-to-a-mdos-platform-api-host_1","text":"Before we can start using the mdos CLI, we need to tell it what MDos API server to talk to. To configure the target MDos platform API server endpoint with your CLI, use the following command: mdos configure api-endpoint https://mdos-api.mydomain.com Note If you installed the MDos Framework platform using the mdos CLI onto your cluster from the same machine than the one you are doing this tutorial from, then you can skip this step since the CLI is already configured. Otherwise, replace the endpoint URL https://mdos-api.mydomain.com with the actual URL you configured to access the MDos API server You are now ready to start using the platform.","title":"Configure your CLI to point to a MDos platform API host"},{"location":"getting-started/#create-a-tenant-namespace_1","text":"In Kubernetes, namespaces are used to group assets together so that they can be properly administered & run in their own scoped context. In MDos, we assign a dedicated namespace to each tenant on the platform. Applications belong to a tenant namespace, without the namespace we can not deploy our application. To create a new tenant namespace called a-team , run the following command: mdos namespace create ? Enter a namespace name to create: a-team Creating namespace... done","title":"Create a tenant namespace"},{"location":"getting-started/#create-a-new-application_1","text":"Let's create a new application project using the mdos CLI command: mdos generate application ? Enter a application name: hello-world ? Enter a tenant name that this application belongs to: a-team This will create a new folder with the mdos.yaml configuration file in it. We are now ready to create application components.","title":"Create a new application"},{"location":"getting-started/#create-a-new-application-component_1","text":"Inside your application project folder, run the following command: cd hello-world mdos generate component ? Enter a application component name: hello-world-server ? What network policy do you want to apply to this component: private (No one can talk to this component) ? Is the component image accessible publicly? Yes ? Does your target registry require authentication to pull images? No Private / Public Registries In MDos framework only mode, there is no private registry available with the platform. Therefore the CLI will ask you a couple of extra questions in order to specify a potential private registry of your own. If that registry requires you to authenticate with it in order to pull & push images from / to the registry, you will have the possibility to specify a secret reference name that holds those credentials as well. This will create a new component folder with an empty Dockerfile for you to use, as well as update the mdos.yaml file referencing the component as part of the overall application project along with it's configuration parameters. You can now go ahead and implement your hello-world-server application component. Let's do just that. We will create a basic NodeJS HTTP server for this demonstration that will return \"hello world\" when invoked. Create a new file: hello-world/hello-world-server/index.js index.js 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 const http = require ( 'http' ); // Loads the http module http . createServer (( request , response ) => { // 1. Tell the browser everything is OK (Status code 200), and the data is in plain text response . writeHead ( 200 , { 'Content-Type' : 'text/plain' }); // 2. Write the announced text to the body of the page response . write ( 'Hello, World!\\n' ); // 3. Tell the server that all of the response headers and body have been sent response . end (); }). listen ( 8080 ); // 4. Tells the server what port to be on Last but not least, we need to populate our component Dockerfile so that we can build our container image during deployments. Open the Dockerfile that is inside the hello-world-server folder and set it's content to the following: Dockerfile 1 2 3 4 5 6 7 8 9 10 FROM node:16 # Create app directory WORKDIR /usr/src/app # Bundle app source COPY ./index.js . EXPOSE 8080 CMD [ \"node\" , \"index.js\" ] Ok, we have an application ready to use now. Next, we need to tell our mdos application that we want to expose port 8080 , and set up an ingress config to expose it outside of the cluster using the hostname hello-world.mydomain.com . Let's start with exposing port 8080 for our application component, which can be done with a kubernetes service . Move into the hello-world-server component folder and execute the following command: mdos generate service ? Enter a name for the service to add a port to: http ? Specify a port number on which your application needs to be accessible on: 8080 And finally, the ingress so that we have a hostname configured to access this application: mdos generate ingress ? Enter a name for the ingress: http-ingress ? What hostname do you want to use to access your component port: hello-world.mydomain.com ? Do you want to match a subpath for this host? No ? What target port should this traffic be redirected to? 8080 ? What type of traffic will this ingress handle? http Note on domain name and DNS resolution It is up to you to make sure that the domain name you choose is resolved by your DNS configuration to point to the Kubernetes cluster IP address. the ingress config will take care of redirecting the traffic to your application component. That's it, this is what your project file structure should look like now: Project structure hello-world \u251c\u2500\u2500 hello-world-server \u2502 \u251c\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 server.js \u2514\u2500\u2500 mdos.yaml Let's have a look at the generated code in the mdos.yaml file: mdos.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 schemaVersion : v1 tenantName : a-team appName : hello-world uuid : mvx10-x2wip components : - name : hello-world-server image : hello-world uuid : qx8su-jwqvi tag : 0.0.1 services : - name : http ports : - port : 8080 ingress : - name : http-ingress matchHost : hello-world.mydomain.com targetPort : 8080 trafficType : HTTP Note All application configuration features will live inside this yaml file, even for the most advanced use-cases and config needs, everything will be here. No need to get dirty with low level kubernetes assets to make it all happen, the platform will translate it all into the proper artefact for you. To learn more about everything that you can configure for your deployments in this yaml file, please check out the MDos application reference documentation","title":"Create a new application component"},{"location":"getting-started/#deploy-your-hello-world-application-on-the-cluster_1","text":"Move into the hello-world application and execute the command: mdos application deploy Synching volumes... done To push your images to your registry, you need to provide your docker hub username and password first ? Username: foobar ? Password: ******** Building application image hello-world:0.0.1... done Pushing application image hello-world:0.0.1... done Deploying application... scheduled Pod: hello-world-server Phase: Running Container: hello-world-hello-world-server State: running Details: n/a SUCCESS : Application deployed That's it, your application should now be accessible on the following domain: https://hello-world.mydomain.com Next steps Please have a look at the chapter MDos application reference documentation for a complete list of what you can configure in the mdos.yaml file.","title":"Deploy your hello-world application on the cluster"},{"location":"installation/","text":"Installation & setup Install the MDos managed cluster platform (Kubernetes cluster & extensions) Info At the moment, the MDos platform has been tested on Ubuntu >= 20.04 and Debian >= buster . I am currently working on porting the platform to CentOS as well, but it is not ready yet. Other versions for those 2 distributions might work, but I have not tested them. The MDos CLI is available for MacOS , linux and Windows First, clone this repo on your target machine: git clone -b v2.0.3 https://github.com/mdundek/mdos.git Before you start The installation will require that you configure a valid domain name and a certificate for the mdos base platform (for development purposes you can choose to work with a self-signed certificate and by editing your /etc/hosts file. This will prevent certain features to work, such as SSO for instance. It is recommended to have a real domain name and a valid certificate for the full experience). If you plan on using cert-manager to manage your certificate, then you will have to prepare a Issuer yaml file upfront before you go ahead and start the installation script (see bellow for an example using a CloudFlare issuer). LoadBalancers & Ports You will have to ensure that traffic to the following ports is routed for the following domain names from anywhere you wish to interact with the MDos platform from. So if you have load balancers in place, please route the following traffic for the following domains & ports to your target node IP address: Domain Port Description keycloak .YOUR_DOMAIN 30999 User to administer your Keycloak instance and to authenticate your users mdos-api .YOUR_DOMAIN 443 The MDos API platform REST interface, used by the MDos CLI mdos-ftp-api .YOUR_DOMAIN 443 The MDOs FTP Server admin API REST interface, used by the MDos CLI & Controller mdos-ftp .YOUR_DOMAIN 3915-3920 The FTP Ports used to transfer data to / from the FTP server registry .YOUR_DOMAIN 443 The private Docker registry registry-auth .YOUR_DOMAIN 443 The private Docker registry authentication server longhorn .YOUR_DOMAIN 443 Longhorn storage solution administrative console grafana .YOUR_DOMAIN 443 Grafana Dashboard for your Loki log aggregator Master node & MDos control plane Install the platform by calling the following script as root: sudo ./mdos-setup/install.sh The MDos platform has a few dependencies, you will need to consent so that the script is allowed to install and configure those dependencies: During the installation procedure, you will be asked to provide a few details. You will have to start by providing your MDos platform host IP address. Then select if you would like to automatically configure the host firewall in order to allow the required traffic policies for MDos. Firewall rules If you choose to NOT let the script configure your firewall, then configure the following firewall rules to allow the platform to run properly: Port Protocol Description 443 TCP Kubernetes hosted applications, routed through the Ingress LoadBalancer Port 6443 TCP Kube-API REST server 30999 TCP Keycloak NodePort, needed to circumvent IstioIngress for OAuth2 purposes 3915 - 3920 TCP MDos FTP Server port 179 TCP Calico BGP Port 4789 UDP Calico networking with VXLAN enabled 2379 TCP etcd client requests 2380 TCP etcd peer communication 10250 TCP Anonymous authentication is disabled. X509 client certificate is required 10255 TCP Read only port for the Kubelet. 10259 & 10257 TCP Serve HTTPS with authentication and authorization. Administrator credentials The platform will create a overall admin account on the platform. Please provide the admin username, email and password first: Domain & certificate setup Some of the components such as the registry auth server require a TLS certificate to function. The installation script will give you multiple choices here: You have a valid certificate at hand that you would like to use You want to set up cert-manager to generate and manage your certificate (Let's Encrypt, CloudFlare, Vault, AWS, Google...) You have no certificate and would like to create a self-signed certificate (only suited for development purposes) Warning For development purposes, you can have the platform generate a self signed certificate for you, but SSO / OIDC functionality will not work with a self-signed certificate. For production, you will have to use a fully valid certificate in order to use all of MDos features. Cert-manager example Self-signed certificate example Here we are using cert-manager to generate and manage the certificate for you Example Issuer must use the name mdos-issuer , the rest is up to you. Here is an example Issuer yaml file that uses CloudFlare as the DNS registrar & Let's Encrypt to generate and sign your certificate: issuer.yaml apiVersion : v1 kind : Secret metadata : name : cloudflare-api-key-secret type : Opaque stringData : api-key : <YOUR CLOUDFLARE API KEY> --- apiVersion : cert-manager.io/v1 kind : Issuer metadata : name : mdos-issuer spec : acme : email : <YOUR LETS-ENCRYPT EMAIL ADDRESS> server : https://acme-v02.api.letsencrypt.org/directory privateKeySecretRef : name : letsencrypt-prod solvers : - dns01 : cloudflare : email : <YOUR CLOUDFLARE EMAIL ADDRESS> apiKeySecretRef : name : cloudflare-api-key-secret key : api-key Other examples for various providers can be found at: https://cert-manager.io/docs/configuration/acme/dns01/#supported-dns01-providers This example is based on the 3rd option, a self signed certificate. If you want to use cert-manager instead (good option for production environment), you will be asked to enter the path to your cert-manager Issuer Yaml file to use in order to issue your certificate. Kubernetes workload storage directory path When you deploy applications onto your Kubernetes cluster, chances are that your applications will require to use permanent / persisted storage. Containers by default do not persist data beyond a container restart, You will therefore have to persist your container data on Kubernetes managed storage. MDos uses Longhorn from Rancher as a storage class. Longhorn will store your container volume data in a dedicated directory on each Cluster Node. This is your chance to customize this directory path in case you want to store this data on an external hard drive that you mounted onto your host system. Please note that you need to ensure that you have enough storage capacity on this directory path, it is recommended to mount a separate dedicated disk for this purpose: Note Longhorn is a block storage provider, it replicates your data over multiple disks / partitions. Longhorn does work with only one disk, which is it's default setup configuration, but it is highly recommended that you configure at least 2, ideally 3 disks for optimal data redundancy. To configure those disk, on the same machine or on different machines, use the longhorn UI accessible under the URL https://longhorn.<ROOT-DOMAIN> Private registry max size MDos comes with a private registry where you can store your images on. The Kubernetes cluster is configured to use this registry if that's what you want to do in order to keep your images in house. This is also a must if you intend to run the platform in offline mode. The registry runs in Kubernetes, it therefore needs to allocate some storage to it so that it can persist it's data on your disk. Here you need to specify how much space you wish to allocate to this registry (in Gigabytes). Note Please note that this storage capacity will be located on your main Kubernetes storage path specified above FTP sync server for Kubernetes POD data provisionning When running applications in kubernetes using CSI storage plugins, you usually end up with a blank volume once your pod starts for the first time. This is usually a pain point for many developers who end up using hostPath mount points instead. This is an anti-pattern and does not go well with multi-node cluster environments where you can not easily predict where your pod is going to start. MDos provides you with a means to initialize your application pods with data pre-allocated to it's volumes. This can be very useful for use cases such as (but not only): Provision a volume with a already pre-established database schema and data set for initialization purposes (or any other type of initialization data sets) Provision static data such as websites or for anything else for that matter... This is achieved by providing a centralized storage space on the mdos platform where a FTP server will allow you to (using the mdos CLI) mirror your application volume data from your local machine to the centralized FTP storage device where Kubernetes will then mirror those data volumes onto your POD volumes using initContainers and the FTP protocol. Here you are being asked to provide a directory path to where this centralized data will be hosted. Again, this is your chance to customize this directory path in case you want to store this data on an external hard drive that you mounted onto your host system: Configure Keycloak and set up the master token After a few minutes (can take up to 10 minutes, depending on your internet speed), you will be asked to set up Keycloak and provide a secret token to the installation script. This token is necessary so that mdos can administer everything it needs on Keycloak. The script provides you with detailed instructions on how to do so, simply follow them and enter the secret token from the Keycloak website. To finalize the setup, do the following: 1. Open a browser and go to: https://keycloak.mydomain.com/admin/master/console/#/realms/master/clients 2. From the 'Clients' section, click on the client 'master-realm' 3. Change 'Access Type' value to 'confidential' 4. Enable the boolean value 'Service Accounts Enabled' 5. Set 'Valid Redirect URIs' value to '*' 6. Save those changes (button at the bottom of the page) 7. In tab 'Roles', Click on button 'edit' for role 'manage realm'. Enable 'Composite roles' and add 'admin' realm to associated roles 8. Go to the 'Service Account Roles' tab and add the role 'admin' to the 'Assigned Roles' box 9. Click on tab 'Credentials' 10. When ready, copy and paste the 'Secret' value into this terminal, then press enter: SECRET: cXXyx8EtGGL8BgCC9zVYQidKYuctzuXA That's it, once the installation script is finished you are ready to use the platform. Worker nodes To add a new worker node to your mdos cluster deployment, clone the mdso repo on the new node machine and execute the following script as root: sudo ./mdos-setup/install-worker.sh This process is straight forward. Simply follow the instructions and you will have a new worker node in your cluster: INFO: Update system and install dependencies... Your firewall is currently disabled. Do you want to enable it now and configure the necessary ports for the platform? > Yes > No Command may disrupt existing ssh connections. Proceed with operation ( y | n ) ? y Firewall is active and enabled on system startup MDos K3S master node host IP address: 192 .168.50.177 To allow this worker node to join the MDos K3S Cluster, a \"Node-token\" is required. You can find this token on the Master node by executing the command: sudo cat /var/lib/rancher/k3s/server/node-token K3S Master node-token: K1006ae41f56fc2f08eeb1d3ead2863347bc9785a9672f12fd31cb310cc0a9658ea::server:a6b26d8340c023c847e86b64b66416154684 INFO: Installing K3S worker node... INFO: Setting up firewall rules... INFO: Cleaning up... Log details of the installation can be found here: /root/11_11_2022_10_29_37_mdos_install.log INFO: Done! Firewall rules If you choose to not let the script configure your firewall, the configure the following firewall rules to allow the platform to run: Port Protocol Description 443 TCP Kubernetes hosted applications, routed through the Ingress LoadBalancer Port 6443 TCP Kube-API REST server 30999 TCP Keycloak NodePort, needed to circumvent IstioIngress for OAuth2 purposes 179 TCP Calico BGP Port 4789 UDP Calico networking with VXLAN enabled 2379 TCP etcd client requests 2380 TCP etcd peer communication 10250 TCP Anonymous authentication is disabled. X509 client certificate is required 10255 TCP Read only port for the Kubelet. Install the MDos framework only onto your existing Kubernetes cluster Installing the MDos framework on an existing Kubernetes cluster is straight forward using the MDos CLI. Before you start Prerequisite A Kubernetes cluster that has a default StorageClass and Ingress controller configured (check with the commands kubectl get storageclass & kubectl get ingressclass ) The kubectl CLI needs to be installed The kubectl default context needs to be configured to point to your Kubernetes cluster (look into the command kubectl config ... for more details) The mdos CLI needs to be installed (Please refer to the section Install the MDos CLI for further information) Install the MDos API server Once those prerequisites are fulfilled, you can go ahead and install the MDos API onto your cluster: mdos install-framework INFO : Target cluster URL: https://192.168.50.179:6443 ? Install MDos onto this cluster? Yes ? What domain name should be used to expose your MDos API server through the Ingress controller: mdos-api.mydomain.com ? Configure a TLS ( HTTPS ) certificate for this domain name? No Installing MDos API server... done Waiting for MDos to start... done Configure your CLI endpoint... done SUCCESS : MDos was installed successfully During the installation, you will be asked to provide a resolvable domain name that will be used to access the MDos API server. To avoid exposing specific NodePorts on the cluster and call the MDos API server using a IP address, we use the Clusters default Ingress controller to configure this access. This is why an actual valid domain name is necessary here. Workaround If you do not have the possibility to configure your DNS server for such a domain to point to your Kubernetes cluster, then configure your local /etc/hosts file to resolve a domain name of your choosing to the Kubernetes Cluster IP address. That's it, you can now start building & deploying your applications using the MDos CLI. Install the MDos CLI Linux & Mac OSX The standalone install is a simple tarball with a binary. It contains its own node.js binary and auto updates. To set up the CLI in /usr/local/lib/mdos and /usr/local/bin/mdos , run the following script. The script requires sudo and isn\u2019t Windows compatible . # Install latest version curl -s https://raw.githubusercontent.com/mdundek/mdos/main/mdos-cli/infra/install-linux-mac.sh | sudo bash To install a specific version of the CLI, do: # NOTE: the version in this example might be outdated. This example is simply to # showcase how you can install a specific version of the CLI in case your mdos server # installation is on an older version curl -s https://raw.githubusercontent.com/mdundek/mdos/main/mdos-cli/infra/install-linux-mac.sh | sudo bash -s -- v1.2.0 Windows Go to the release page for MDos here and download the latest exe file for the CLI. Make sure your exe file is on your system PATH. Verify Your Installation To verify your CLI installation, use the mdos --version command: mdos --version mdos-cli/0.0.0 linux-x64 node-v18.9.0 Special notes about self-signed certificates without a resolvable DNS name For development purposes, you can use self-signed certificates without a publicly available DNS name. That said, you will have to configure your hosts file from wherever you wish to use the CLI from so that it can resolve the various hostname used by the MDos API platform. Note Please replace XXX.XXX.XXX.XXX with the MDos Platform server IP address, and mydomain.com with the actual domain used when you deployed the MDos platform. Linux & Mac OSX Open your /etc/hosts file (root user) and add the following entries to it: XXX.XXX.XXX.XXX registry.mydomain.com registry-auth.mydomain.com mdos-api.mydomain.com mdos-ftp.mydomain.com mdos-ftp-api.mydomain.com longhorn.mydomain.com Note Please replace XXX.XXX.XXX.XXX with the MDos Platform server IP address, and mydomain.com with the actual domain used when you deployed the MDos platform. Windows Open your c:\\Windows\\System32\\Drivers\\etc\\hosts file (root user) and add the following entries to it: XXX.XXX.XXX.XXX registry.mydomain.com XXX.XXX.XXX.XXX registry-auth.mydomain.com XXX.XXX.XXX.XXX mdos-api.mydomain.com XXX.XXX.XXX.XXX mdos-ftp.mydomain.com XXX.XXX.XXX.XXX mdos-ftp-api.mydomain.com XXX.XXX.XXX.XXX longhorn.mydomain.com XXX.XXX.XXX.XXX grafana.mydomain.com","title":"Install"},{"location":"installation/#installation-setup","text":"","title":"Installation &amp; setup"},{"location":"installation/#install-the-mdos-managed-cluster-platform-kubernetes-cluster-extensions","text":"Info At the moment, the MDos platform has been tested on Ubuntu >= 20.04 and Debian >= buster . I am currently working on porting the platform to CentOS as well, but it is not ready yet. Other versions for those 2 distributions might work, but I have not tested them. The MDos CLI is available for MacOS , linux and Windows First, clone this repo on your target machine: git clone -b v2.0.3 https://github.com/mdundek/mdos.git","title":"Install the MDos managed cluster platform (Kubernetes cluster &amp; extensions)"},{"location":"installation/#before-you-start","text":"The installation will require that you configure a valid domain name and a certificate for the mdos base platform (for development purposes you can choose to work with a self-signed certificate and by editing your /etc/hosts file. This will prevent certain features to work, such as SSO for instance. It is recommended to have a real domain name and a valid certificate for the full experience). If you plan on using cert-manager to manage your certificate, then you will have to prepare a Issuer yaml file upfront before you go ahead and start the installation script (see bellow for an example using a CloudFlare issuer). LoadBalancers & Ports You will have to ensure that traffic to the following ports is routed for the following domain names from anywhere you wish to interact with the MDos platform from. So if you have load balancers in place, please route the following traffic for the following domains & ports to your target node IP address: Domain Port Description keycloak .YOUR_DOMAIN 30999 User to administer your Keycloak instance and to authenticate your users mdos-api .YOUR_DOMAIN 443 The MDos API platform REST interface, used by the MDos CLI mdos-ftp-api .YOUR_DOMAIN 443 The MDOs FTP Server admin API REST interface, used by the MDos CLI & Controller mdos-ftp .YOUR_DOMAIN 3915-3920 The FTP Ports used to transfer data to / from the FTP server registry .YOUR_DOMAIN 443 The private Docker registry registry-auth .YOUR_DOMAIN 443 The private Docker registry authentication server longhorn .YOUR_DOMAIN 443 Longhorn storage solution administrative console grafana .YOUR_DOMAIN 443 Grafana Dashboard for your Loki log aggregator","title":"Before you start"},{"location":"installation/#master-node-mdos-control-plane","text":"Install the platform by calling the following script as root: sudo ./mdos-setup/install.sh The MDos platform has a few dependencies, you will need to consent so that the script is allowed to install and configure those dependencies: During the installation procedure, you will be asked to provide a few details. You will have to start by providing your MDos platform host IP address. Then select if you would like to automatically configure the host firewall in order to allow the required traffic policies for MDos. Firewall rules If you choose to NOT let the script configure your firewall, then configure the following firewall rules to allow the platform to run properly: Port Protocol Description 443 TCP Kubernetes hosted applications, routed through the Ingress LoadBalancer Port 6443 TCP Kube-API REST server 30999 TCP Keycloak NodePort, needed to circumvent IstioIngress for OAuth2 purposes 3915 - 3920 TCP MDos FTP Server port 179 TCP Calico BGP Port 4789 UDP Calico networking with VXLAN enabled 2379 TCP etcd client requests 2380 TCP etcd peer communication 10250 TCP Anonymous authentication is disabled. X509 client certificate is required 10255 TCP Read only port for the Kubelet. 10259 & 10257 TCP Serve HTTPS with authentication and authorization.","title":"Master node &amp; MDos control plane"},{"location":"installation/#administrator-credentials","text":"The platform will create a overall admin account on the platform. Please provide the admin username, email and password first:","title":" Administrator credentials"},{"location":"installation/#domain-certificate-setup","text":"Some of the components such as the registry auth server require a TLS certificate to function. The installation script will give you multiple choices here: You have a valid certificate at hand that you would like to use You want to set up cert-manager to generate and manage your certificate (Let's Encrypt, CloudFlare, Vault, AWS, Google...) You have no certificate and would like to create a self-signed certificate (only suited for development purposes) Warning For development purposes, you can have the platform generate a self signed certificate for you, but SSO / OIDC functionality will not work with a self-signed certificate. For production, you will have to use a fully valid certificate in order to use all of MDos features. Cert-manager example Self-signed certificate example Here we are using cert-manager to generate and manage the certificate for you Example Issuer must use the name mdos-issuer , the rest is up to you. Here is an example Issuer yaml file that uses CloudFlare as the DNS registrar & Let's Encrypt to generate and sign your certificate: issuer.yaml apiVersion : v1 kind : Secret metadata : name : cloudflare-api-key-secret type : Opaque stringData : api-key : <YOUR CLOUDFLARE API KEY> --- apiVersion : cert-manager.io/v1 kind : Issuer metadata : name : mdos-issuer spec : acme : email : <YOUR LETS-ENCRYPT EMAIL ADDRESS> server : https://acme-v02.api.letsencrypt.org/directory privateKeySecretRef : name : letsencrypt-prod solvers : - dns01 : cloudflare : email : <YOUR CLOUDFLARE EMAIL ADDRESS> apiKeySecretRef : name : cloudflare-api-key-secret key : api-key Other examples for various providers can be found at: https://cert-manager.io/docs/configuration/acme/dns01/#supported-dns01-providers This example is based on the 3rd option, a self signed certificate. If you want to use cert-manager instead (good option for production environment), you will be asked to enter the path to your cert-manager Issuer Yaml file to use in order to issue your certificate.","title":" Domain &amp; certificate setup"},{"location":"installation/#kubernetes-workload-storage-directory-path","text":"When you deploy applications onto your Kubernetes cluster, chances are that your applications will require to use permanent / persisted storage. Containers by default do not persist data beyond a container restart, You will therefore have to persist your container data on Kubernetes managed storage. MDos uses Longhorn from Rancher as a storage class. Longhorn will store your container volume data in a dedicated directory on each Cluster Node. This is your chance to customize this directory path in case you want to store this data on an external hard drive that you mounted onto your host system. Please note that you need to ensure that you have enough storage capacity on this directory path, it is recommended to mount a separate dedicated disk for this purpose: Note Longhorn is a block storage provider, it replicates your data over multiple disks / partitions. Longhorn does work with only one disk, which is it's default setup configuration, but it is highly recommended that you configure at least 2, ideally 3 disks for optimal data redundancy. To configure those disk, on the same machine or on different machines, use the longhorn UI accessible under the URL https://longhorn.<ROOT-DOMAIN>","title":" Kubernetes workload storage directory path"},{"location":"installation/#private-registry-max-size","text":"MDos comes with a private registry where you can store your images on. The Kubernetes cluster is configured to use this registry if that's what you want to do in order to keep your images in house. This is also a must if you intend to run the platform in offline mode. The registry runs in Kubernetes, it therefore needs to allocate some storage to it so that it can persist it's data on your disk. Here you need to specify how much space you wish to allocate to this registry (in Gigabytes). Note Please note that this storage capacity will be located on your main Kubernetes storage path specified above","title":" Private registry max size"},{"location":"installation/#ftp-sync-server-for-kubernetes-pod-data-provisionning","text":"When running applications in kubernetes using CSI storage plugins, you usually end up with a blank volume once your pod starts for the first time. This is usually a pain point for many developers who end up using hostPath mount points instead. This is an anti-pattern and does not go well with multi-node cluster environments where you can not easily predict where your pod is going to start. MDos provides you with a means to initialize your application pods with data pre-allocated to it's volumes. This can be very useful for use cases such as (but not only): Provision a volume with a already pre-established database schema and data set for initialization purposes (or any other type of initialization data sets) Provision static data such as websites or for anything else for that matter... This is achieved by providing a centralized storage space on the mdos platform where a FTP server will allow you to (using the mdos CLI) mirror your application volume data from your local machine to the centralized FTP storage device where Kubernetes will then mirror those data volumes onto your POD volumes using initContainers and the FTP protocol. Here you are being asked to provide a directory path to where this centralized data will be hosted. Again, this is your chance to customize this directory path in case you want to store this data on an external hard drive that you mounted onto your host system:","title":" FTP sync server for Kubernetes POD data provisionning"},{"location":"installation/#configure-keycloak-and-set-up-the-master-token","text":"After a few minutes (can take up to 10 minutes, depending on your internet speed), you will be asked to set up Keycloak and provide a secret token to the installation script. This token is necessary so that mdos can administer everything it needs on Keycloak. The script provides you with detailed instructions on how to do so, simply follow them and enter the secret token from the Keycloak website. To finalize the setup, do the following: 1. Open a browser and go to: https://keycloak.mydomain.com/admin/master/console/#/realms/master/clients 2. From the 'Clients' section, click on the client 'master-realm' 3. Change 'Access Type' value to 'confidential' 4. Enable the boolean value 'Service Accounts Enabled' 5. Set 'Valid Redirect URIs' value to '*' 6. Save those changes (button at the bottom of the page) 7. In tab 'Roles', Click on button 'edit' for role 'manage realm'. Enable 'Composite roles' and add 'admin' realm to associated roles 8. Go to the 'Service Account Roles' tab and add the role 'admin' to the 'Assigned Roles' box 9. Click on tab 'Credentials' 10. When ready, copy and paste the 'Secret' value into this terminal, then press enter: SECRET: cXXyx8EtGGL8BgCC9zVYQidKYuctzuXA That's it, once the installation script is finished you are ready to use the platform.","title":" Configure Keycloak and set up the master token"},{"location":"installation/#worker-nodes","text":"To add a new worker node to your mdos cluster deployment, clone the mdso repo on the new node machine and execute the following script as root: sudo ./mdos-setup/install-worker.sh This process is straight forward. Simply follow the instructions and you will have a new worker node in your cluster: INFO: Update system and install dependencies... Your firewall is currently disabled. Do you want to enable it now and configure the necessary ports for the platform? > Yes > No Command may disrupt existing ssh connections. Proceed with operation ( y | n ) ? y Firewall is active and enabled on system startup MDos K3S master node host IP address: 192 .168.50.177 To allow this worker node to join the MDos K3S Cluster, a \"Node-token\" is required. You can find this token on the Master node by executing the command: sudo cat /var/lib/rancher/k3s/server/node-token K3S Master node-token: K1006ae41f56fc2f08eeb1d3ead2863347bc9785a9672f12fd31cb310cc0a9658ea::server:a6b26d8340c023c847e86b64b66416154684 INFO: Installing K3S worker node... INFO: Setting up firewall rules... INFO: Cleaning up... Log details of the installation can be found here: /root/11_11_2022_10_29_37_mdos_install.log INFO: Done! Firewall rules If you choose to not let the script configure your firewall, the configure the following firewall rules to allow the platform to run: Port Protocol Description 443 TCP Kubernetes hosted applications, routed through the Ingress LoadBalancer Port 6443 TCP Kube-API REST server 30999 TCP Keycloak NodePort, needed to circumvent IstioIngress for OAuth2 purposes 179 TCP Calico BGP Port 4789 UDP Calico networking with VXLAN enabled 2379 TCP etcd client requests 2380 TCP etcd peer communication 10250 TCP Anonymous authentication is disabled. X509 client certificate is required 10255 TCP Read only port for the Kubelet.","title":"Worker nodes"},{"location":"installation/#install-the-mdos-framework-only-onto-your-existing-kubernetes-cluster","text":"Installing the MDos framework on an existing Kubernetes cluster is straight forward using the MDos CLI.","title":"Install the MDos framework only onto your existing Kubernetes cluster"},{"location":"installation/#before-you-start_1","text":"Prerequisite A Kubernetes cluster that has a default StorageClass and Ingress controller configured (check with the commands kubectl get storageclass & kubectl get ingressclass ) The kubectl CLI needs to be installed The kubectl default context needs to be configured to point to your Kubernetes cluster (look into the command kubectl config ... for more details) The mdos CLI needs to be installed (Please refer to the section Install the MDos CLI for further information)","title":"Before you start"},{"location":"installation/#install-the-mdos-api-server","text":"Once those prerequisites are fulfilled, you can go ahead and install the MDos API onto your cluster: mdos install-framework INFO : Target cluster URL: https://192.168.50.179:6443 ? Install MDos onto this cluster? Yes ? What domain name should be used to expose your MDos API server through the Ingress controller: mdos-api.mydomain.com ? Configure a TLS ( HTTPS ) certificate for this domain name? No Installing MDos API server... done Waiting for MDos to start... done Configure your CLI endpoint... done SUCCESS : MDos was installed successfully During the installation, you will be asked to provide a resolvable domain name that will be used to access the MDos API server. To avoid exposing specific NodePorts on the cluster and call the MDos API server using a IP address, we use the Clusters default Ingress controller to configure this access. This is why an actual valid domain name is necessary here. Workaround If you do not have the possibility to configure your DNS server for such a domain to point to your Kubernetes cluster, then configure your local /etc/hosts file to resolve a domain name of your choosing to the Kubernetes Cluster IP address. That's it, you can now start building & deploying your applications using the MDos CLI.","title":"Install the MDos API server"},{"location":"installation/#install-the-mdos-cli","text":"","title":"Install the MDos CLI"},{"location":"installation/#linux-mac-osx","text":"The standalone install is a simple tarball with a binary. It contains its own node.js binary and auto updates. To set up the CLI in /usr/local/lib/mdos and /usr/local/bin/mdos , run the following script. The script requires sudo and isn\u2019t Windows compatible . # Install latest version curl -s https://raw.githubusercontent.com/mdundek/mdos/main/mdos-cli/infra/install-linux-mac.sh | sudo bash To install a specific version of the CLI, do: # NOTE: the version in this example might be outdated. This example is simply to # showcase how you can install a specific version of the CLI in case your mdos server # installation is on an older version curl -s https://raw.githubusercontent.com/mdundek/mdos/main/mdos-cli/infra/install-linux-mac.sh | sudo bash -s -- v1.2.0","title":"Linux &amp; Mac OSX"},{"location":"installation/#windows","text":"Go to the release page for MDos here and download the latest exe file for the CLI. Make sure your exe file is on your system PATH.","title":"Windows"},{"location":"installation/#verify-your-installation","text":"To verify your CLI installation, use the mdos --version command: mdos --version mdos-cli/0.0.0 linux-x64 node-v18.9.0","title":"Verify Your Installation"},{"location":"installation/#special-notes-about-self-signed-certificates-without-a-resolvable-dns-name","text":"For development purposes, you can use self-signed certificates without a publicly available DNS name. That said, you will have to configure your hosts file from wherever you wish to use the CLI from so that it can resolve the various hostname used by the MDos API platform. Note Please replace XXX.XXX.XXX.XXX with the MDos Platform server IP address, and mydomain.com with the actual domain used when you deployed the MDos platform.","title":"Special notes about self-signed certificates without a resolvable DNS name"},{"location":"installation/#linux-mac-osx_1","text":"Open your /etc/hosts file (root user) and add the following entries to it: XXX.XXX.XXX.XXX registry.mydomain.com registry-auth.mydomain.com mdos-api.mydomain.com mdos-ftp.mydomain.com mdos-ftp-api.mydomain.com longhorn.mydomain.com Note Please replace XXX.XXX.XXX.XXX with the MDos Platform server IP address, and mydomain.com with the actual domain used when you deployed the MDos platform.","title":" Linux &amp; Mac OSX"},{"location":"installation/#windows_1","text":"Open your c:\\Windows\\System32\\Drivers\\etc\\hosts file (root user) and add the following entries to it: XXX.XXX.XXX.XXX registry.mydomain.com XXX.XXX.XXX.XXX registry-auth.mydomain.com XXX.XXX.XXX.XXX mdos-api.mydomain.com XXX.XXX.XXX.XXX mdos-ftp.mydomain.com XXX.XXX.XXX.XXX mdos-ftp-api.mydomain.com XXX.XXX.XXX.XXX longhorn.mydomain.com XXX.XXX.XXX.XXX grafana.mydomain.com","title":" Windows"},{"location":"reference-documentation/","text":"MDos application reference documentation Anatomy of an application Applications are to be seen as a higher level concept, an application in mdos is composed of one or more application components. Application components are your actual project asset placeholders (source code), where one component could be an API backend server for instance, and a second component would hold your front end application and so on. Every application component can have one or more volumes attached to it for storage persistance & data mirroring. This architecture allows you to compose complex applications to suit your needs. A MDos application project layout is composed of one or more folders, each one representing an application component. At the root of the application folder is a mdos.Please Noteyaml file that holds all runtime configuration parameters for the application and it's components: MDos managed cluster MDos framework only Project structure my-application/ \u251c\u2500\u2500 backend \u2502 \u2514\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 <your application code files>... \u251c\u2500\u2500 frontend \u2502 \u2514\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 <your application code files>... \u251c\u2500\u2500 volumes \u2502 \u2514\u2500\u2500 static-website \u2502 \u2514\u2500\u2500 index.html \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 mdos.yaml In this example we have an application named my-application , that is composed of two distinct application components: backend & frontend . Each component has it's own Dockerfile. At the application level, there is also a volumes folder where you can store application component volume files to be used within your application, and a mdos.yaml config file that holds all runtime configuration parameters. As an example, here the volumes folder has a subfolder called static-website that is used by the frontend application so serve it's website data. Note Volumes are managed on the application level rather than on the component level in case you wish to share volumes amongst components. Project structure my-application/ \u251c\u2500\u2500 backend \u2502 \u2514\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 <your application code files>... \u251c\u2500\u2500 frontend \u2502 \u2514\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 <your application code files>... \u2514\u2500\u2500 mdos.yaml In this example we have an application named my-application , that is composed of two distinct application components: backend & frontend . Each component has it's own Dockerfile. At the application level, there is also a mdos.yaml config file that holds all runtime configuration parameters. Manifest file: mdos.yaml Each application is configured in a YAML file at the root of the application folder. This is the equivalent of your lower level Kubernetes yaml files, but all concatenated into a single, higher level configuration file that greatly abstracts away the complexity of Kubernetes deployment. We will now have a closer look at what you can configure in your application mdos.yaml file. Application Each mdos.yaml file starts with global configuration parameters specific to this application: 1 2 3 4 5 schemaVersion : v1 tenantName : my-team appName : my-application uuid : XA74S-FXCDI components : [ ... ] The tenant-name field maps directly to a kubernetes target namespace . The uuid field is a unique identifier for this application, all dependant resources that this application will create and manage will be tied to this application uuid . CLI command mdos generate application Application component Each application component will translate to a specific deployment on the cluster. Just like an application, a component has some base values that need to be set: 1 2 3 4 5 6 7 8 9 10 11 12 ... components : - name : comp-1 image : my-comp-1-img-name tag : 1.0.0 uuid : E5PLU-TQMBD ... - name : comp-2 image : my-comp-2-img-name tag : 1.0.0 uuid : HUJKG-GDGHN ... Among those, you will define your component name , image name and image tag to use. CLI command mdos generate component When using the MDos CLI to scaffold your application component, then the CLI will ask you to select amongst multiple network isolation options. You can read more about NetworkPolicy isolation configurations in the section here Registries Registries are where your MDos will push and pull your application images to/from. Multiple choices are available here. Use the MDos registry Please note Only applicable for MDos managed cluster deployments MDos comes with a private integrated Docker registry. If no registry parameter is set on your component yaml block, then this private internal registry will be used to push / pull the images from. No extra configuration parameters are required if this is the registry you want to use. 1 2 3 4 5 6 7 ... components : - name : comp-1 ... image : my-comp-1-img-name tag : 1.0.0 ... Use a custom registry If you have your own private registry that you would like to use for your application images, you can do so by specifying a registry value on your component, along with an optionnal imagePullSecrets value that should be used to authenticate with your registry: 1 2 3 4 5 6 7 8 9 10 ... components : - name : comp-1 ... image : my-comp-1-img-name tag : 1.0.0 registry : my.private.registry imagePullSecrets : # Optionnal - name : my-registry-secret ... Note Since you are using your own private registry, it will be up to you to provision your private registry Secret on the target namespace. Use a public registry The third option is to use a public registry, again with an optionnal imagePullSecrets value that should be used to authenticate with the public registry: MDos managed cluster MDos framework only 1 2 3 4 5 6 7 8 9 components : - name : comp-1 ... image : my-comp-1-img-name tag : 1.0.0 publicRegistry : true imagePullSecrets : # Optionnal - name : my-registry-secret ... 1 2 3 4 5 6 7 8 components : - name : comp-1 ... image : my-comp-1-img-name tag : 1.0.0 imagePullSecrets : # Optionnal - name : my-registry-secret ... Disable image builds on deploy In some cases, you might not want to build your image when you deploy your applications using the command mdos application deploy . This could be the case if you use DevOps pipelines (GitHub Pipelines, Jenkins...) that already take care of building your images for you. In this case, simply add the flag doNotBuild: true to your component to disable this behavior for a given component: 1 2 3 4 5 6 7 components : - name : comp-1 ... image : my-comp-1-img-name tag : 1.0.0 doNotBuild : true ... Note As mentioned above, if you use this flag, make sure your images are present in the target registries before deploying. Overwrite container default command on start If you wish to overwrite the command used by a container on startup, you can so so like this: 1 2 3 4 5 6 7 8 9 10 ... components : - name : comp-1 ... command : - \"sh\" - \"-c\" - \"mycommand\" workingDir : /from/this/dir # optional ... or along with command augments: 1 2 3 4 5 6 7 8 ... components : - name : comp-1 ... command : [ \"printenv\" ] commandArgs : [ \"HOSTNAME\" , \"KUBERNETES_PORT\" ] workingDir : /from/this/dir # optional ... Persisted Volumes Volumes in Kubernetes come in all sorts and chapes. The most common one being the Persisted Volume to store your application data, but volumes can also be composed of files stored as ConfigMaps and Secrets, or a combination of both. Let's have a look at the various ways to use volumes in MDos. Standard volumes This is the de-facto volume type, standard volumes are PersistedVolumes in Kubernetes, they start out empty (see them as a new partition that get's mounted onto your application environment) so that you can write data to it and ensure this data is persisted even on reboots, crashes... Volumes are defined by a name , a mountPath that indicates where this volume partition needs to be mounted onto your application POD, and a size parameter to indicate what size this volume should have (size of the volume partition to be allocated). 1 2 3 4 5 6 7 8 9 ... components : - name : comp-1 ... volumes : - name : database-storage mountPath : /usr/data/db size : 10Gi ... The default StorageClass is based on the open source project Longhorn , a Block Storage solution that is very convenient and versatile. CLI command mdos generate volume Shared volumes Please note Only applicable for MDos managed cluster deployments Shared volumes are NFS based volumes that can be shared amongst multiple application components. To use them, those volumes need to be created upfront using the following command: mdos shared-volume create Once this volume is created on the cluster, you can reference this volume in your application components: 1 2 3 4 5 6 7 8 9 ... components : - name : comp-1 ... volumes : - name : database-storage mountPath : /usr/data/db sharedVolumeName : my-shared-volume # existing shared-volume ... CLI command mdos shared-volume create mdos generate volume Pre-populate volumes Please note Only applicable for MDos managed cluster deployments This MDos feature is designed to facilitate the way you can pre-populate files and folders into your volumes before your application starts up. This is useful when you wish to pre-load a database with a pre-defined dataset, or to deploy a static website for example. Your MDos project contains a volumes folder at the root, create a volume folder in there and store your static data in it. Then add the flag syncVolume: true to your volume config like this: 1 2 3 4 5 6 7 8 9 10 11 ... components : - name : comp-1 ... volumes : - name : static-website mountPath : /usr/share/nginx/html syncVolume : true trigger : initial # or \"always\" size : 10Gi ... \"trigger\" possible values Description initial Synchronize local volume content only if the POD target volume is empty (first deployment) always Synchronize local volume content every time this application is deployed Example volume folder structure in your MDos project folder: Project structure 1 2 3 4 5 6 ... \u251c\u2500\u2500 volumes \u2502 \u2514\u2500\u2500 static-website \u2502 \u2514\u2500\u2500 index.html \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 mdos.yaml Then, when you deploy your application using the command mdos application deploy , this data will be synchronized with your application component volume before it starts. CLI command mdos generate volume HostPath mounts HostPath volumes do not use PersistedVolumes , they are direct mount points from the host file system with the application container. Those volume types are not recommended, they do not scale and are only recommended for debugging purposes. 1 2 3 4 5 6 7 8 9 ... components : - name : comp-1 ... volumes : - name : database-storage mountPath : /usr/data/db hostPath : /path/to/folder/on/node ... CLI command mdos generate volume ReadOnly volumes & files Read-only volumes are volumes that contain data such as certificates, scripts or any other type of files that your applications depend on to work. Using Secrets You can create and mount a Kubernetes Secret as a volume mount point using two different approaches: Mount as directory Mount as files Here, your secret will be mounted as a directory, meaning that all values from your secret will be available as files inside your mountPath directory. Changing secret values This is a good approach if your Secret get's updated from time to time, this way of mounting Secrets in a Kubernetes ensures that those updated values are reflected back in the mounted files inside your PODs without restarting them. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ... components : - name : comp-1 ... secrets : - name : my-ca type : dir mountPath : /etc/x509/https entries : - key : ca.crt value : |- -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- - key : ca.key value : |- -----BEGIN EC PRIVATE KEY----- ... -----END EC PRIVATE KEY----- ... In this case, you can mount individual files from a Secret, rather than a whole secret. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ... components : - name : comp-1 ... secrets : - name : my-ca type : file mountPath : /etc/x509/https entries : - key : client-ca filename : ca.crt value : |- -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- - key : client-key filename : ca.key value : |- -----BEGIN EC PRIVATE KEY----- ... -----END EC PRIVATE KEY----- ... CLI command mdos generate secret Using ConfigMaps You can create and mount a Kubernetes ConfigMaps as a volume mount point using two different approaches: Mount as directory Mount as files Here, your secret will be mounted as a directory, meaning that all values from your ConfigMap will be available as files inside your mountPath directory. Changing ConfigMap values This is a good approach if your ConfigMap get's updated from time to time, this way of mounting ConfigMaps in a Kubernetes ensures that those updated values are reflected back in the mounted files inside your PODs without restarting them. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ... components : - name : comp-1 ... configs : - name : my-ca type : dir mountPath : /etc/my-scripts defaultMode : 0744 # optional entries : - key : foo.sh value : |- #!/bin/sh echo \"Hello world from foo!\" - key : bar.sh value : |- #!/bin/sh echo \"Hello world from bar!\" ... In this case, you can mount individual files from a ConfigMap, rather than a whole ConfigMap. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ... components : - name : comp-1 ... configs : - name : my-ca type : file mountPath : /etc/my-scripts defaultMode : 0744 # optional entries : - key : foo-script filename : foo.sh value : |- #!/bin/sh echo \"Hello world from foo!\" - key : bar-script filename : bar.sh value : |- #!/bin/sh echo \"Hello world from bar!\" ... CLI command mdos generate config From existing ConfigMap or Secret It is also possible to mount Secrets or ConfigMaps from external references inside your container POD's, rather than creating those objects along with your application deployments. This is useful if you need to decouple the lifecycle of your Secrets or ConfigMaps from your actual applications themselves. As an example, imagine a Secret that holds your application certificate data that is managed by Cert-Manager , those secrets might get updated in any point in time and your application deployment should in no way overwrite this Secret data on deployments. In this case, you will simply reference the target secret you wish to mount. Of course, those Secrets and/or ConfigMaps should exist upfront before you deploy your applications that make use of them. Mount as directory Mount as files 1 2 3 4 5 6 7 8 9 10 ... components : - name : comp-1 ... secrets : # or configs - name : my-ca type : dir mountPath : /etc/x509/https ref : my-root-domain-tls-secret # existing secret / configMap name to reference ... 1 2 3 4 5 6 7 8 9 10 11 12 13 ... components : - name : comp-1 ... secrets : # or configs - name : my-ca type : file mountPath : /etc/x509/https ref : my-root-domain-tls-secret # existing secret / configMap name to reference entries : - key : ca-crt # name of the configMap / secret key that contains the value filename : ca.crt # name of the file to use to mount this value as ... CLI command mdos generate secret or mdos generate config Environment Variables Environment variables are a core concept of almost any cloud application. They can also be content sensitive in some cases (ex. passwords, private keys...), in which case you should consider using Kubernetes Secrets rather than ConfigMaps , or directly coding those as environment variables in your deployment YAML files. Using ConfigMaps or Secrets If all you need is to set environment variables for your application components, use the following example: As Secret As ConfigMap 1 2 3 4 5 6 7 8 9 10 11 12 13 ... components : - name : comp-1 ... secrets : - name : config-params type : env entries : - key : MY_VAR_1 value : \"my vlaue\" - key : MY_VAR_2 value : \"my other vlaue\" ... 1 2 3 4 5 6 7 8 9 10 11 12 13 ... components : - name : comp-1 ... configs : - name : config-params type : env entries : - key : MY_VAR_1 value : \"my vlaue\" - key : MY_VAR_2 value : \"my other vlaue\" ... CLI command mdos generate secret or mdos generate config From existing ConfigMap or Secret It is also possible to reference Secrets or ConfigMaps from external references inside your container POD's, rather than creating those objects along with your application deployments. Of course, those Secrets and/or ConfigMaps should exist upfront before you deploy your applications that make use of them. From existing Secret From existing ConfigMap 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ... components : - name : comp-1 ... secrets : - name : rabbitmq-creds type : env ref : rabbitmq-cluster-default-user # existing secret / configMap name to reference entries : - name : RABBIT_PORT # variable name to set key : PORT # variable key name from the ref. secret / config - name : RABBIT_HOST key : HOST ... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ... components : - name : comp-1 ... configs : - name : rabbitmq-creds type : env ref : rabbitmq-cluster-default-user # existing secret / configMap name to reference entries : - name : RABBIT_PORT # variable name to set key : PORT # variable key name from the ref. secret / config - name : RABBIT_HOST key : HOST ... CLI command mdos generate secret or mdos generate config Networking Exposing ports using services Applications often expose services using a specific port(s). Remember, in Kubernetes, POD IP addresses are ephemeral. They change every time your POD is restarted. To allow applications to talk to your application services, you need a Kubernetes Service object to allow your application component to be auto-discoverable by other application components, hens the Service in Kubernetes. To create a service endpoint for your various ports, use the following syntax: 1 2 3 4 5 6 7 8 9 ... components : - name : comp-1 ... services : - name : http-service ports : - port : 80 ... CLI command mdos generate service Configure Ingress By default, applications in Kubernetes are only reachable from other components that are also running inside your cluster. To make application component services accessible from outside your cluster, you will have to add an ingress to your application component, this will expose this service endpoint to the outside world using a host / domain name. MDos managed cluster MDos framework only 1 2 3 4 5 6 7 8 9 10 ... components : - name : comp-1 ... ingress : - name : main matchHost : nginx.mydomain.com targetPort : 80 trafficType : http ... \"trafficType\" possible values Description http The ingress will be configured to route traffic coming from port 80 to the port specified in targetPort https The ingress will be configured to route traffic coming from port 443 to the port specified in targetPort Note If your matchHost value is a subdomain of your root MDos domain name configured during the platform installation and your traffic type is https , then nothing else is needed for ingress to work OOTB. Now if you would like to use a different host / domain name to respond to your traffic for this component ingress, then you will have to create a ingress-gateway object first using the command mdos ingress-gateway create . For more details, refer back to the chapter Managing your Domain specific Ingress-Gateways . 1 2 3 4 5 6 7 8 9 10 11 12 ... components : - name : comp-1 ... ingress : - name : main matchHost : nginx.mydomain.com targetPort : 80 trafficType : HTTPS_SIMPLE tlsSecretName : myTlsSecret ... \"trafficType\" possible values Description HTTP The ingress will be configured to route traffic coming from port 80 to the port specified in targetPort HTTPS_SIMPLE The ingress will be configured to route traffic coming from port 443 and terminate the TLS connection before routing the traffic to the port specified in targetPort . If set, a secret reference name holding the TLS certificate details (crt & key) needs to be provided as well HTTPS_PASSTHROUGH The ingress will be configured to route traffic coming from port 443 to the port specified in targetPort as is, the application will need to listen for incoming HTTPS traffic and terminate the TLS connection there CLI command mdos ingress-gateway create mdos generate ingress NetworkPolicy On a multi-tenant cluster environement, it is important that you protect your components from being accessed from other application components. There are 4 available configuration settings available for you to use: Scope Description private No one can talk to this component limited Only components belonging to this application can talk to this component open All application components in this tenant namespace can talk to this component custom You can specify which components in what namespaces can talk to this component This is how you configure this on your component: 1 2 3 4 5 6 7 ... components : - name : comp-1 ... networkPolicy : scope : private # limited | open | custom ... The custom scope let's you specify specifically what application components from what namespaces are allowed to communicate with this component. Here is a more complex example that uses a custom scoped NetworkPolicy (please note the addition of the allow array value in this case): Component dependencies If your component has a strong dependency with one or more of your application components, and it should wait until those components are up and running before starting this component, then use the flag dependsOn : 1 2 3 4 5 6 7 8 9 ... components : - name : postgres ... - name : comp-1 ... dependsOn : - postgres ... This will provision a initContainer that will monitor your other components, effectively delaying it's start up until those conditions are met. OAuth2 OIDC Please note Only applicable for MDos managed cluster deployments You can protect your applications using OAuth2 OIDC without having to write a single line of code or modify your applications in any way. You have the option of a variaty of OIDC providers such as Keycloak, Google, GitHub and others. To find out how to configure and add your OIDC providers, please refer to the chapter Securing applications using OIDC providers for more information. Protect your ingress with a OIDC provider To add OIDC authentication to one of your application configurations, simply specify which OIDC provider you want to enforce, and what hostname that was configured in your ingres section you want to be protected. There are numerous OOTB providers that you can configure, but the most flexible and customizable is the integrated Keycloak OIDC provider. It will allow you to create any role according to your needs, assign them to your users and gain access to those roles from your authenticated user sessions encoded in the JWT token. Simply use those roles within your applications to then determine fine grained ACL rules you wish to enforce. Info For an example using the Keycloak OIDC authentication provider with custom roles and ACL, please refer to the chapter Securing applications using OIDC providers 1 2 3 4 5 6 7 8 9 ... components : - name : comp-1 ... oidc : provider : google-test-provider hosts : - nginx.mydomain.com ... CLI command mdos application protect Set pod resources This allows you to impose limits in terms of CPU / memory resources you application components can use. 1 2 3 4 5 6 7 8 9 10 11 12 ... components : - name : comp-1 ... resources : requests : memory : \"64Mi\" cpu : \"250m\" limits : memory : \"128Mi\" cpu : \"500m\" ... Execute pre-build commands MDos allows you to execute commands on the local machine every time you are about to deploy your application onto your Kubernetes cluster. Simply list the commands you wish to execute, and they will execute every time you run the command mdos application deploy . In this example, we are building a mkdocs project, then copy the resulting files over to the proper volumes directory ready for deployment 1 2 3 4 5 6 7 8 9 ... components : - name : comp-1 ... preBuildCmd : - mkdocs build - rm -rf ../volumes/docs/* - cp -r ./site/* ../volumes/docs ...","title":"Reference Documentation"},{"location":"reference-documentation/#mdos-application-reference-documentation","text":"","title":"MDos application reference documentation"},{"location":"reference-documentation/#anatomy-of-an-application","text":"Applications are to be seen as a higher level concept, an application in mdos is composed of one or more application components. Application components are your actual project asset placeholders (source code), where one component could be an API backend server for instance, and a second component would hold your front end application and so on. Every application component can have one or more volumes attached to it for storage persistance & data mirroring. This architecture allows you to compose complex applications to suit your needs. A MDos application project layout is composed of one or more folders, each one representing an application component. At the root of the application folder is a mdos.Please Noteyaml file that holds all runtime configuration parameters for the application and it's components: MDos managed cluster MDos framework only Project structure my-application/ \u251c\u2500\u2500 backend \u2502 \u2514\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 <your application code files>... \u251c\u2500\u2500 frontend \u2502 \u2514\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 <your application code files>... \u251c\u2500\u2500 volumes \u2502 \u2514\u2500\u2500 static-website \u2502 \u2514\u2500\u2500 index.html \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 mdos.yaml In this example we have an application named my-application , that is composed of two distinct application components: backend & frontend . Each component has it's own Dockerfile. At the application level, there is also a volumes folder where you can store application component volume files to be used within your application, and a mdos.yaml config file that holds all runtime configuration parameters. As an example, here the volumes folder has a subfolder called static-website that is used by the frontend application so serve it's website data. Note Volumes are managed on the application level rather than on the component level in case you wish to share volumes amongst components. Project structure my-application/ \u251c\u2500\u2500 backend \u2502 \u2514\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 <your application code files>... \u251c\u2500\u2500 frontend \u2502 \u2514\u2500\u2500 Dockerfile \u2502 \u2514\u2500\u2500 <your application code files>... \u2514\u2500\u2500 mdos.yaml In this example we have an application named my-application , that is composed of two distinct application components: backend & frontend . Each component has it's own Dockerfile. At the application level, there is also a mdos.yaml config file that holds all runtime configuration parameters.","title":"Anatomy of an application"},{"location":"reference-documentation/#manifest-file-mdosyaml","text":"Each application is configured in a YAML file at the root of the application folder. This is the equivalent of your lower level Kubernetes yaml files, but all concatenated into a single, higher level configuration file that greatly abstracts away the complexity of Kubernetes deployment. We will now have a closer look at what you can configure in your application mdos.yaml file.","title":"Manifest file: mdos.yaml"},{"location":"reference-documentation/#application","text":"Each mdos.yaml file starts with global configuration parameters specific to this application: 1 2 3 4 5 schemaVersion : v1 tenantName : my-team appName : my-application uuid : XA74S-FXCDI components : [ ... ] The tenant-name field maps directly to a kubernetes target namespace . The uuid field is a unique identifier for this application, all dependant resources that this application will create and manage will be tied to this application uuid . CLI command mdos generate application","title":"Application"},{"location":"reference-documentation/#application-component","text":"Each application component will translate to a specific deployment on the cluster. Just like an application, a component has some base values that need to be set: 1 2 3 4 5 6 7 8 9 10 11 12 ... components : - name : comp-1 image : my-comp-1-img-name tag : 1.0.0 uuid : E5PLU-TQMBD ... - name : comp-2 image : my-comp-2-img-name tag : 1.0.0 uuid : HUJKG-GDGHN ... Among those, you will define your component name , image name and image tag to use. CLI command mdos generate component When using the MDos CLI to scaffold your application component, then the CLI will ask you to select amongst multiple network isolation options. You can read more about NetworkPolicy isolation configurations in the section here","title":"Application component"},{"location":"reference-documentation/#registries","text":"Registries are where your MDos will push and pull your application images to/from. Multiple choices are available here.","title":" Registries"},{"location":"reference-documentation/#use-the-mdos-registry","text":"Please note Only applicable for MDos managed cluster deployments MDos comes with a private integrated Docker registry. If no registry parameter is set on your component yaml block, then this private internal registry will be used to push / pull the images from. No extra configuration parameters are required if this is the registry you want to use. 1 2 3 4 5 6 7 ... components : - name : comp-1 ... image : my-comp-1-img-name tag : 1.0.0 ...","title":" Use the MDos registry"},{"location":"reference-documentation/#use-a-custom-registry","text":"If you have your own private registry that you would like to use for your application images, you can do so by specifying a registry value on your component, along with an optionnal imagePullSecrets value that should be used to authenticate with your registry: 1 2 3 4 5 6 7 8 9 10 ... components : - name : comp-1 ... image : my-comp-1-img-name tag : 1.0.0 registry : my.private.registry imagePullSecrets : # Optionnal - name : my-registry-secret ... Note Since you are using your own private registry, it will be up to you to provision your private registry Secret on the target namespace.","title":" Use a custom registry"},{"location":"reference-documentation/#use-a-public-registry","text":"The third option is to use a public registry, again with an optionnal imagePullSecrets value that should be used to authenticate with the public registry: MDos managed cluster MDos framework only 1 2 3 4 5 6 7 8 9 components : - name : comp-1 ... image : my-comp-1-img-name tag : 1.0.0 publicRegistry : true imagePullSecrets : # Optionnal - name : my-registry-secret ... 1 2 3 4 5 6 7 8 components : - name : comp-1 ... image : my-comp-1-img-name tag : 1.0.0 imagePullSecrets : # Optionnal - name : my-registry-secret ...","title":" Use a public registry"},{"location":"reference-documentation/#disable-image-builds-on-deploy","text":"In some cases, you might not want to build your image when you deploy your applications using the command mdos application deploy . This could be the case if you use DevOps pipelines (GitHub Pipelines, Jenkins...) that already take care of building your images for you. In this case, simply add the flag doNotBuild: true to your component to disable this behavior for a given component: 1 2 3 4 5 6 7 components : - name : comp-1 ... image : my-comp-1-img-name tag : 1.0.0 doNotBuild : true ... Note As mentioned above, if you use this flag, make sure your images are present in the target registries before deploying.","title":" Disable image builds on deploy"},{"location":"reference-documentation/#overwrite-container-default-command-on-start","text":"If you wish to overwrite the command used by a container on startup, you can so so like this: 1 2 3 4 5 6 7 8 9 10 ... components : - name : comp-1 ... command : - \"sh\" - \"-c\" - \"mycommand\" workingDir : /from/this/dir # optional ... or along with command augments: 1 2 3 4 5 6 7 8 ... components : - name : comp-1 ... command : [ \"printenv\" ] commandArgs : [ \"HOSTNAME\" , \"KUBERNETES_PORT\" ] workingDir : /from/this/dir # optional ...","title":" Overwrite container default command on start"},{"location":"reference-documentation/#persisted-volumes","text":"Volumes in Kubernetes come in all sorts and chapes. The most common one being the Persisted Volume to store your application data, but volumes can also be composed of files stored as ConfigMaps and Secrets, or a combination of both. Let's have a look at the various ways to use volumes in MDos.","title":" Persisted Volumes"},{"location":"reference-documentation/#standard-volumes","text":"This is the de-facto volume type, standard volumes are PersistedVolumes in Kubernetes, they start out empty (see them as a new partition that get's mounted onto your application environment) so that you can write data to it and ensure this data is persisted even on reboots, crashes... Volumes are defined by a name , a mountPath that indicates where this volume partition needs to be mounted onto your application POD, and a size parameter to indicate what size this volume should have (size of the volume partition to be allocated). 1 2 3 4 5 6 7 8 9 ... components : - name : comp-1 ... volumes : - name : database-storage mountPath : /usr/data/db size : 10Gi ... The default StorageClass is based on the open source project Longhorn , a Block Storage solution that is very convenient and versatile. CLI command mdos generate volume","title":" Standard volumes"},{"location":"reference-documentation/#shared-volumes","text":"Please note Only applicable for MDos managed cluster deployments Shared volumes are NFS based volumes that can be shared amongst multiple application components. To use them, those volumes need to be created upfront using the following command: mdos shared-volume create Once this volume is created on the cluster, you can reference this volume in your application components: 1 2 3 4 5 6 7 8 9 ... components : - name : comp-1 ... volumes : - name : database-storage mountPath : /usr/data/db sharedVolumeName : my-shared-volume # existing shared-volume ... CLI command mdos shared-volume create mdos generate volume","title":" Shared volumes"},{"location":"reference-documentation/#pre-populate-volumes","text":"Please note Only applicable for MDos managed cluster deployments This MDos feature is designed to facilitate the way you can pre-populate files and folders into your volumes before your application starts up. This is useful when you wish to pre-load a database with a pre-defined dataset, or to deploy a static website for example. Your MDos project contains a volumes folder at the root, create a volume folder in there and store your static data in it. Then add the flag syncVolume: true to your volume config like this: 1 2 3 4 5 6 7 8 9 10 11 ... components : - name : comp-1 ... volumes : - name : static-website mountPath : /usr/share/nginx/html syncVolume : true trigger : initial # or \"always\" size : 10Gi ... \"trigger\" possible values Description initial Synchronize local volume content only if the POD target volume is empty (first deployment) always Synchronize local volume content every time this application is deployed Example volume folder structure in your MDos project folder: Project structure 1 2 3 4 5 6 ... \u251c\u2500\u2500 volumes \u2502 \u2514\u2500\u2500 static-website \u2502 \u2514\u2500\u2500 index.html \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 mdos.yaml Then, when you deploy your application using the command mdos application deploy , this data will be synchronized with your application component volume before it starts. CLI command mdos generate volume","title":" Pre-populate volumes"},{"location":"reference-documentation/#hostpath-mounts","text":"HostPath volumes do not use PersistedVolumes , they are direct mount points from the host file system with the application container. Those volume types are not recommended, they do not scale and are only recommended for debugging purposes. 1 2 3 4 5 6 7 8 9 ... components : - name : comp-1 ... volumes : - name : database-storage mountPath : /usr/data/db hostPath : /path/to/folder/on/node ... CLI command mdos generate volume","title":" HostPath mounts"},{"location":"reference-documentation/#readonly-volumes-files","text":"Read-only volumes are volumes that contain data such as certificates, scripts or any other type of files that your applications depend on to work.","title":" ReadOnly volumes &amp; files"},{"location":"reference-documentation/#using-secrets","text":"You can create and mount a Kubernetes Secret as a volume mount point using two different approaches: Mount as directory Mount as files Here, your secret will be mounted as a directory, meaning that all values from your secret will be available as files inside your mountPath directory. Changing secret values This is a good approach if your Secret get's updated from time to time, this way of mounting Secrets in a Kubernetes ensures that those updated values are reflected back in the mounted files inside your PODs without restarting them. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ... components : - name : comp-1 ... secrets : - name : my-ca type : dir mountPath : /etc/x509/https entries : - key : ca.crt value : |- -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- - key : ca.key value : |- -----BEGIN EC PRIVATE KEY----- ... -----END EC PRIVATE KEY----- ... In this case, you can mount individual files from a Secret, rather than a whole secret. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ... components : - name : comp-1 ... secrets : - name : my-ca type : file mountPath : /etc/x509/https entries : - key : client-ca filename : ca.crt value : |- -----BEGIN CERTIFICATE----- ... -----END CERTIFICATE----- - key : client-key filename : ca.key value : |- -----BEGIN EC PRIVATE KEY----- ... -----END EC PRIVATE KEY----- ... CLI command mdos generate secret","title":" Using Secrets"},{"location":"reference-documentation/#using-configmaps","text":"You can create and mount a Kubernetes ConfigMaps as a volume mount point using two different approaches: Mount as directory Mount as files Here, your secret will be mounted as a directory, meaning that all values from your ConfigMap will be available as files inside your mountPath directory. Changing ConfigMap values This is a good approach if your ConfigMap get's updated from time to time, this way of mounting ConfigMaps in a Kubernetes ensures that those updated values are reflected back in the mounted files inside your PODs without restarting them. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ... components : - name : comp-1 ... configs : - name : my-ca type : dir mountPath : /etc/my-scripts defaultMode : 0744 # optional entries : - key : foo.sh value : |- #!/bin/sh echo \"Hello world from foo!\" - key : bar.sh value : |- #!/bin/sh echo \"Hello world from bar!\" ... In this case, you can mount individual files from a ConfigMap, rather than a whole ConfigMap. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ... components : - name : comp-1 ... configs : - name : my-ca type : file mountPath : /etc/my-scripts defaultMode : 0744 # optional entries : - key : foo-script filename : foo.sh value : |- #!/bin/sh echo \"Hello world from foo!\" - key : bar-script filename : bar.sh value : |- #!/bin/sh echo \"Hello world from bar!\" ... CLI command mdos generate config","title":" Using ConfigMaps"},{"location":"reference-documentation/#from-existing-configmap-or-secret","text":"It is also possible to mount Secrets or ConfigMaps from external references inside your container POD's, rather than creating those objects along with your application deployments. This is useful if you need to decouple the lifecycle of your Secrets or ConfigMaps from your actual applications themselves. As an example, imagine a Secret that holds your application certificate data that is managed by Cert-Manager , those secrets might get updated in any point in time and your application deployment should in no way overwrite this Secret data on deployments. In this case, you will simply reference the target secret you wish to mount. Of course, those Secrets and/or ConfigMaps should exist upfront before you deploy your applications that make use of them. Mount as directory Mount as files 1 2 3 4 5 6 7 8 9 10 ... components : - name : comp-1 ... secrets : # or configs - name : my-ca type : dir mountPath : /etc/x509/https ref : my-root-domain-tls-secret # existing secret / configMap name to reference ... 1 2 3 4 5 6 7 8 9 10 11 12 13 ... components : - name : comp-1 ... secrets : # or configs - name : my-ca type : file mountPath : /etc/x509/https ref : my-root-domain-tls-secret # existing secret / configMap name to reference entries : - key : ca-crt # name of the configMap / secret key that contains the value filename : ca.crt # name of the file to use to mount this value as ... CLI command mdos generate secret or mdos generate config","title":" From existing ConfigMap or Secret"},{"location":"reference-documentation/#environment-variables","text":"Environment variables are a core concept of almost any cloud application. They can also be content sensitive in some cases (ex. passwords, private keys...), in which case you should consider using Kubernetes Secrets rather than ConfigMaps , or directly coding those as environment variables in your deployment YAML files.","title":" Environment Variables"},{"location":"reference-documentation/#using-configmaps-or-secrets","text":"If all you need is to set environment variables for your application components, use the following example: As Secret As ConfigMap 1 2 3 4 5 6 7 8 9 10 11 12 13 ... components : - name : comp-1 ... secrets : - name : config-params type : env entries : - key : MY_VAR_1 value : \"my vlaue\" - key : MY_VAR_2 value : \"my other vlaue\" ... 1 2 3 4 5 6 7 8 9 10 11 12 13 ... components : - name : comp-1 ... configs : - name : config-params type : env entries : - key : MY_VAR_1 value : \"my vlaue\" - key : MY_VAR_2 value : \"my other vlaue\" ... CLI command mdos generate secret or mdos generate config","title":" Using ConfigMaps or Secrets"},{"location":"reference-documentation/#from-existing-configmap-or-secret_1","text":"It is also possible to reference Secrets or ConfigMaps from external references inside your container POD's, rather than creating those objects along with your application deployments. Of course, those Secrets and/or ConfigMaps should exist upfront before you deploy your applications that make use of them. From existing Secret From existing ConfigMap 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ... components : - name : comp-1 ... secrets : - name : rabbitmq-creds type : env ref : rabbitmq-cluster-default-user # existing secret / configMap name to reference entries : - name : RABBIT_PORT # variable name to set key : PORT # variable key name from the ref. secret / config - name : RABBIT_HOST key : HOST ... 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ... components : - name : comp-1 ... configs : - name : rabbitmq-creds type : env ref : rabbitmq-cluster-default-user # existing secret / configMap name to reference entries : - name : RABBIT_PORT # variable name to set key : PORT # variable key name from the ref. secret / config - name : RABBIT_HOST key : HOST ... CLI command mdos generate secret or mdos generate config","title":" From existing ConfigMap or Secret"},{"location":"reference-documentation/#networking","text":"","title":" Networking"},{"location":"reference-documentation/#exposing-ports-using-services","text":"Applications often expose services using a specific port(s). Remember, in Kubernetes, POD IP addresses are ephemeral. They change every time your POD is restarted. To allow applications to talk to your application services, you need a Kubernetes Service object to allow your application component to be auto-discoverable by other application components, hens the Service in Kubernetes. To create a service endpoint for your various ports, use the following syntax: 1 2 3 4 5 6 7 8 9 ... components : - name : comp-1 ... services : - name : http-service ports : - port : 80 ... CLI command mdos generate service","title":" Exposing ports using services"},{"location":"reference-documentation/#configure-ingress","text":"By default, applications in Kubernetes are only reachable from other components that are also running inside your cluster. To make application component services accessible from outside your cluster, you will have to add an ingress to your application component, this will expose this service endpoint to the outside world using a host / domain name. MDos managed cluster MDos framework only 1 2 3 4 5 6 7 8 9 10 ... components : - name : comp-1 ... ingress : - name : main matchHost : nginx.mydomain.com targetPort : 80 trafficType : http ... \"trafficType\" possible values Description http The ingress will be configured to route traffic coming from port 80 to the port specified in targetPort https The ingress will be configured to route traffic coming from port 443 to the port specified in targetPort Note If your matchHost value is a subdomain of your root MDos domain name configured during the platform installation and your traffic type is https , then nothing else is needed for ingress to work OOTB. Now if you would like to use a different host / domain name to respond to your traffic for this component ingress, then you will have to create a ingress-gateway object first using the command mdos ingress-gateway create . For more details, refer back to the chapter Managing your Domain specific Ingress-Gateways . 1 2 3 4 5 6 7 8 9 10 11 12 ... components : - name : comp-1 ... ingress : - name : main matchHost : nginx.mydomain.com targetPort : 80 trafficType : HTTPS_SIMPLE tlsSecretName : myTlsSecret ... \"trafficType\" possible values Description HTTP The ingress will be configured to route traffic coming from port 80 to the port specified in targetPort HTTPS_SIMPLE The ingress will be configured to route traffic coming from port 443 and terminate the TLS connection before routing the traffic to the port specified in targetPort . If set, a secret reference name holding the TLS certificate details (crt & key) needs to be provided as well HTTPS_PASSTHROUGH The ingress will be configured to route traffic coming from port 443 to the port specified in targetPort as is, the application will need to listen for incoming HTTPS traffic and terminate the TLS connection there CLI command mdos ingress-gateway create mdos generate ingress","title":" Configure Ingress"},{"location":"reference-documentation/#networkpolicy","text":"On a multi-tenant cluster environement, it is important that you protect your components from being accessed from other application components. There are 4 available configuration settings available for you to use: Scope Description private No one can talk to this component limited Only components belonging to this application can talk to this component open All application components in this tenant namespace can talk to this component custom You can specify which components in what namespaces can talk to this component This is how you configure this on your component: 1 2 3 4 5 6 7 ... components : - name : comp-1 ... networkPolicy : scope : private # limited | open | custom ... The custom scope let's you specify specifically what application components from what namespaces are allowed to communicate with this component. Here is a more complex example that uses a custom scoped NetworkPolicy (please note the addition of the allow array value in this case):","title":" NetworkPolicy"},{"location":"reference-documentation/#component-dependencies","text":"If your component has a strong dependency with one or more of your application components, and it should wait until those components are up and running before starting this component, then use the flag dependsOn : 1 2 3 4 5 6 7 8 9 ... components : - name : postgres ... - name : comp-1 ... dependsOn : - postgres ... This will provision a initContainer that will monitor your other components, effectively delaying it's start up until those conditions are met.","title":" Component dependencies"},{"location":"reference-documentation/#oauth2-oidc","text":"Please note Only applicable for MDos managed cluster deployments You can protect your applications using OAuth2 OIDC without having to write a single line of code or modify your applications in any way. You have the option of a variaty of OIDC providers such as Keycloak, Google, GitHub and others. To find out how to configure and add your OIDC providers, please refer to the chapter Securing applications using OIDC providers for more information.","title":" OAuth2 OIDC"},{"location":"reference-documentation/#protect-your-ingress-with-a-oidc-provider","text":"To add OIDC authentication to one of your application configurations, simply specify which OIDC provider you want to enforce, and what hostname that was configured in your ingres section you want to be protected. There are numerous OOTB providers that you can configure, but the most flexible and customizable is the integrated Keycloak OIDC provider. It will allow you to create any role according to your needs, assign them to your users and gain access to those roles from your authenticated user sessions encoded in the JWT token. Simply use those roles within your applications to then determine fine grained ACL rules you wish to enforce. Info For an example using the Keycloak OIDC authentication provider with custom roles and ACL, please refer to the chapter Securing applications using OIDC providers 1 2 3 4 5 6 7 8 9 ... components : - name : comp-1 ... oidc : provider : google-test-provider hosts : - nginx.mydomain.com ... CLI command mdos application protect","title":" Protect your ingress with a OIDC provider"},{"location":"reference-documentation/#set-pod-resources","text":"This allows you to impose limits in terms of CPU / memory resources you application components can use. 1 2 3 4 5 6 7 8 9 10 11 12 ... components : - name : comp-1 ... resources : requests : memory : \"64Mi\" cpu : \"250m\" limits : memory : \"128Mi\" cpu : \"500m\" ...","title":" Set pod resources"},{"location":"reference-documentation/#execute-pre-build-commands","text":"MDos allows you to execute commands on the local machine every time you are about to deploy your application onto your Kubernetes cluster. Simply list the commands you wish to execute, and they will execute every time you run the command mdos application deploy . In this example, we are building a mkdocs project, then copy the resulting files over to the proper volumes directory ready for deployment 1 2 3 4 5 6 7 8 9 ... components : - name : comp-1 ... preBuildCmd : - mkdocs build - rm -rf ../volumes/docs/* - cp -r ./site/* ../volumes/docs ...","title":" Execute pre-build commands"}]}